{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c883cb0bd4d475da0daa7069b2188a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03cf8df14fb744e3b2ae79713ea63627",
              "IPY_MODEL_d30e14ea32b2456db77278e02fe9219b",
              "IPY_MODEL_fe729340ee374333845a9bee42d6d0b0",
              "IPY_MODEL_899bee3331a3442192dc6569bd061ab2",
              "IPY_MODEL_45b0391df2834c9f82b4785498db3c7b"
            ],
            "layout": "IPY_MODEL_1080fcc23a9e414580ff0a178c063a73"
          }
        },
        "03cf8df14fb744e3b2ae79713ea63627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c37e85f658444b469114883ab6a1d2c4",
            "placeholder": "​",
            "style": "IPY_MODEL_4fb5fdb222fb428ba8b74972ecc6bf50",
            "value": "<h3>NBA Game Prediction</h3>"
          }
        },
        "d30e14ea32b2456db77278e02fe9219b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7314aec0c15409189489fd6dab5d2dc",
            "placeholder": "​",
            "style": "IPY_MODEL_cf6423da94a64aee8ec200f4312946f0",
            "value": "<p style=\"color: green;\">Models loaded and ready</p>"
          }
        },
        "fe729340ee374333845a9bee42d6d0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_138497201475493db193467240307980",
              "IPY_MODEL_280c1aa78269409d84466829463776ef"
            ],
            "layout": "IPY_MODEL_2f6cd8d7a2b545cc8299dc5a90dce241"
          }
        },
        "899bee3331a3442192dc6569bd061ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_813fb70b2cfb4c6d814344252e8300be",
              "IPY_MODEL_076a40bdc773402ca477b3bd4f254fe7"
            ],
            "layout": "IPY_MODEL_ccb6de02b0b34a7c81f073c6ebf764eb"
          }
        },
        "45b0391df2834c9f82b4785498db3c7b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_75d8df1af7d741038656ae7f42b7d0da",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,535 - INFO - Initial data shape: (1, 28)\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,537 - INFO - Initial columns: Index(['GAME_DATE', 'TEAM_ID', 'TEAM_ABBREVIATION', 'TEAM_NAME',\n",
                  "       'OPPONENT_TEAM_ID', 'OPPONENT_ABBREV', 'MATCHUP', 'WL', 'MIN', 'PTS',\n",
                  "       'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA',\n",
                  "       'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
                  "       'PLUS_MINUS'],\n",
                  "      dtype='object')\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,542 - INFO - Created WIN column from WL\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,545 - INFO - After date conversion shape: (1, 29)\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,551 - INFO - After team abbreviation mapping shape: (1, 29)\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,579 - INFO - After dropping missing opponents shape: (1, 34)\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,607 - INFO - Adding fatigue features...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,625 - INFO - Adding advanced features...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,653 - INFO - Adding rolling stats...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,781 - INFO - Adding head-to-head features...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,790 - INFO - Adding streak features...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,798 - INFO - Adding time-based features...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,799 - INFO - Starting add_time_based_features\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,804 - INFO - Initial shape: (1, 114)\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,813 - INFO - Final shape after time-based features: (1, 117)\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "2024-11-13 19:50:51,831 - INFO - Final shape: (1, 117)\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\n",
                  "Prediction for BKN vs BOS:\n",
                  "Win Probability for BKN: 33.95%\n",
                  "Confidence: 32.10%\n",
                  "\n",
                  "Model Predictions:\n",
                  "Baseline: 47.92%\n",
                  "Xgboost: 9.04%\n",
                  "Lightgbm: 33.55%\n",
                  "Neural_network: 57.95%\n"
                ]
              }
            ]
          }
        },
        "1080fcc23a9e414580ff0a178c063a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c37e85f658444b469114883ab6a1d2c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb5fdb222fb428ba8b74972ecc6bf50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7314aec0c15409189489fd6dab5d2dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf6423da94a64aee8ec200f4312946f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "138497201475493db193467240307980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Home Team:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d00f6198adf747c0901ac48136191501",
            "placeholder": "​",
            "style": "IPY_MODEL_e9eb33218b4941b49e1fa94a60f4449d",
            "value": "BKN"
          }
        },
        "280c1aa78269409d84466829463776ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Away Team:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1cf883756eb34a0d88656b1765730100",
            "placeholder": "​",
            "style": "IPY_MODEL_112262f55d6b42c9aa1f476223f6dde0",
            "value": "BOS"
          }
        },
        "2f6cd8d7a2b545cc8299dc5a90dce241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813fb70b2cfb4c6d814344252e8300be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Train Models",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b933c857ac5340feaca30058a624a269",
            "style": "IPY_MODEL_022c5e5586ff4e0ea7de93240c91c09c",
            "tooltip": ""
          }
        },
        "076a40bdc773402ca477b3bd4f254fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Predict",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c78de212c4824e668e917402c4d3508a",
            "style": "IPY_MODEL_eacac327d2a84e90a7c9040ce0bdc635",
            "tooltip": ""
          }
        },
        "ccb6de02b0b34a7c81f073c6ebf764eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d00f6198adf747c0901ac48136191501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9eb33218b4941b49e1fa94a60f4449d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf883756eb34a0d88656b1765730100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "112262f55d6b42c9aa1f476223f6dde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b933c857ac5340feaca30058a624a269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022c5e5586ff4e0ea7de93240c91c09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c78de212c4824e668e917402c4d3508a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacac327d2a84e90a7c9040ce0bdc635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "75d8df1af7d741038656ae7f42b7d0da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Dependencies\n",
        "# Install necessary packages required for the notebook.\n",
        "\n",
        "!pip install nba_api pandas numpy scikit-learn lightgbm xgboost seaborn matplotlib ipywidgets optuna joblib shap requests tensorflow fastapi uvicorn nest_asyncio pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B-A5R0LTffss",
        "outputId": "d43bc701-db54-4f7d-d9f9-eec89bef6626"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nba_api in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.46.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.32.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.41.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import Libraries and Set Up Environment\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore warning messages\n",
        "\n",
        "# Check if running in Google Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Import data manipulation libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import plotting libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import datetime utilities\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Import machine learning libraries\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "\n",
        "# Import deep learning libraries\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Import Optuna for hyperparameter optimization\n",
        "import optuna\n",
        "\n",
        "# Import SHAP for model interpretation\n",
        "import shap\n",
        "\n",
        "# Import requests and retry adapters\n",
        "import requests\n",
        "from requests.adapters import HTTPAdapter\n",
        "from requests.packages.urllib3.util.retry import Retry\n",
        "\n",
        "# Import NBA API libraries\n",
        "from nba_api.stats.endpoints import leaguegamefinder\n",
        "from nba_api.stats.static import teams\n",
        "\n",
        "# Import FastAPI and Uvicorn for API development\n",
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Import ngrok for exposing local server (optional)\n",
        "if IN_COLAB:\n",
        "    from pyngrok import ngrok\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    force=True\n",
        ")\n",
        "logging.info(\"Logging configured successfully\")\n",
        "\n",
        "# Mount Google Drive if running in Colab\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Set up base directories using pathlib\n",
        "from pathlib import Path\n",
        "\n",
        "base_dir = Path(\"/content/drive/MyDrive/nba_models\") if IN_COLAB else Path(\"nba_models\")\n",
        "cache_dir = base_dir / \"cache\"\n",
        "cache_dir.mkdir(parents=True, exist_ok=True)  # Create directories if they don't exist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH4e9qOdfoeL",
        "outputId": "3ae9ab08-1477-492d-fc0d-54ea54b00dee"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 19:13:53,188 - INFO - Logging configured successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Configuration Class\n",
        "# This class stores all the configuration parameters used throughout the notebook.\n",
        "\n",
        "class NotebookConfig:\n",
        "    # Model parameters for XGBoost and LightGBM\n",
        "    XGB_PARAMS = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'random_state': 42,\n",
        "        'n_estimators': 100,\n",
        "        'eval_metric': 'logloss',\n",
        "        'max_depth': 6,\n",
        "        'learning_rate': 0.1\n",
        "    }\n",
        "\n",
        "    LGB_PARAMS = {\n",
        "        'objective': 'binary',\n",
        "        'random_state': 42,\n",
        "        'n_estimators': 100,\n",
        "        'metric': 'binary_logloss',\n",
        "        'num_leaves': 31,\n",
        "        'learning_rate': 0.1\n",
        "    }\n",
        "\n",
        "    # Training parameters\n",
        "    VALIDATION_WINDOW = 60  # Days\n",
        "    RETRAIN_FREQUENCY = 7   # Days\n",
        "    MIN_TRAINING_SAMPLES = 1000\n",
        "    ROLLING_WINDOWS = [5, 10, 20]  # For rolling statistics\n",
        "    HEAD_TO_HEAD_WINDOW = 10  # Games\n",
        "\n",
        "    # Data parameters\n",
        "    START_SEASON = '2015-16'\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "    # API Configuration for fetching odds data\n",
        "    ODDS_API_KEY = '55bc8ab276ec29e4a474114a4eccb463'  # Replace with your actual API key\n",
        "    ODDS_API_URL = 'https://api.the-odds-api.com/v4/sports/basketball_nba/odds'\n",
        "    ODDS_API_HISTORICAL_URL = 'https://api.the-odds-api.com/v4/sports/basketball_nba/odds-history'\n",
        "    REGIONS = 'us'\n",
        "    MARKETS = 'h2h'\n",
        "    ODDS_FORMAT = 'american'\n",
        "    BOOKMAKERS = 'fanduel'\n",
        "    BATCH_SIZE = 10\n",
        "\n",
        "    # Paths for models and cache directories\n",
        "    MODELS_DIR = base_dir\n",
        "    CACHE_DIR = cache_dir\n",
        "\n",
        "    # Betting parameters\n",
        "    MIN_KELLY_FRACTION = 0.1\n",
        "    MAX_KELLY_FRACTION = 0.5\n",
        "    MIN_CONFIDENCE = 0.6"
      ],
      "metadata": {
        "id": "oXzEfNnefsOe"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Data Manager Class\n",
        "# This class handles data saving, loading, and cache validation.\n",
        "\n",
        "class DataManager:\n",
        "    def __init__(self):\n",
        "        self.config = NotebookConfig()\n",
        "\n",
        "    def get_cache_path(self, filename):\n",
        "        \"\"\"Get the full path to the cache file.\"\"\"\n",
        "        return self.config.CACHE_DIR / filename\n",
        "\n",
        "    def save_data(self, data, filename):\n",
        "        \"\"\"Save data to a cache file using pickle.\"\"\"\n",
        "        cache_path = self.get_cache_path(filename)\n",
        "        with open(cache_path, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "        logging.info(f\"Data saved to {cache_path}\")\n",
        "\n",
        "    def load_data(self, filename):\n",
        "        \"\"\"Load data from a cache file.\"\"\"\n",
        "        cache_path = self.get_cache_path(filename)\n",
        "        if cache_path.exists():\n",
        "            with open(cache_path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "            logging.info(f\"Data loaded from {cache_path}\")\n",
        "            return data\n",
        "        return None\n",
        "\n",
        "    def is_cache_fresh(self, filename, max_age_hours=24):\n",
        "        \"\"\"Check if the cache file is fresh within the specified hours.\"\"\"\n",
        "        cache_path = self.get_cache_path(filename)\n",
        "        try:\n",
        "            if not cache_path.exists():\n",
        "                return False\n",
        "            file_time = datetime.fromtimestamp(cache_path.stat().st_mtime)\n",
        "            return (datetime.now() - file_time).total_seconds() < max_age_hours * 3600\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error checking cache freshness: {e}\")\n",
        "            return False\n"
      ],
      "metadata": {
        "id": "jTkdwm5xfz3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b377db3a-d239-4804-fa9b-ab22d57f93ba"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 19:05:46,565 - INFO - Data saved to /content/drive/MyDrive/nba_models/cache/test_cache.pkl\n",
            "2024-11-13 19:05:46,575 - INFO - Data loaded from /content/drive/MyDrive/nba_models/cache/test_cache.pkl\n",
            "2024-11-13 19:05:46,578 - INFO - DataManager test passed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Data Fetching Functions\n",
        "# These functions handle data fetching from the NBA API with retry logic.\n",
        "\n",
        "def fetch_nba_data_with_retry():\n",
        "    \"\"\"Fetch NBA game data with retry logic.\"\"\"\n",
        "    session = requests.Session()\n",
        "    retry = Retry(total=5, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
        "    adapter = HTTPAdapter(max_retries=retry)\n",
        "    session.mount('https://', adapter)\n",
        "\n",
        "    try:\n",
        "        logging.info(\"Fetching all NBA game data...\")\n",
        "        gamefinder = leaguegamefinder.LeagueGameFinder()\n",
        "        all_games = gamefinder.get_data_frames()[0]\n",
        "        logging.info(f\"Fetched {len(all_games)} games.\")\n",
        "        return all_games\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching NBA data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def fetch_or_load_data():\n",
        "    \"\"\"Fetch data from API or load from cache.\"\"\"\n",
        "    data_manager = DataManager()\n",
        "    cache_filename = 'nba_game_data.pkl'\n",
        "\n",
        "    # Check if cached data is fresh\n",
        "    if data_manager.is_cache_fresh(cache_filename):\n",
        "        cached_data = data_manager.load_data(cache_filename)\n",
        "        if cached_data is not None:\n",
        "            # Ensure GAME_DATE is in datetime format\n",
        "            cached_data['GAME_DATE'] = pd.to_datetime(cached_data['GAME_DATE'])\n",
        "\n",
        "            # Check if new data is available\n",
        "            latest_game_date = cached_data['GAME_DATE'].max()\n",
        "\n",
        "            # Calculate difference in days\n",
        "            if (datetime.now() - latest_game_date).days < 1:\n",
        "                logging.info(\"Cache is fresh, loading data from cache.\")\n",
        "                return cached_data\n",
        "            else:\n",
        "                logging.info(\"Cache is stale, fetching new data.\")\n",
        "        else:\n",
        "            logging.info(\"No cached data found, fetching fresh data.\")\n",
        "\n",
        "    # Fetch new data if cache is unavailable or stale\n",
        "    game_data = fetch_nba_data_with_retry()\n",
        "\n",
        "    # Check if data was fetched successfully before saving\n",
        "    if game_data is not None and not game_data.empty:\n",
        "        data_manager.save_data(game_data, cache_filename)\n",
        "        logging.info(f\"New data fetched and saved to cache with {len(game_data)} games.\")\n",
        "    else:\n",
        "        logging.error(\"Failed to fetch new game data; not saving to cache.\")\n",
        "\n",
        "    return game_data"
      ],
      "metadata": {
        "id": "oddBHX7Cf3-D"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Data Processor Class\n",
        "# This class handles data processing and feature engineering.\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self):\n",
        "        self.config = NotebookConfig()\n",
        "        self.date_odds_cache = {}  # Cache odds data by date\n",
        "        self.batch_odds_data = {}  # Temporary store for batch processing\n",
        "\n",
        "    def prepare_features(self, df):\n",
        "        \"\"\"Prepare features for model training/prediction.\"\"\"\n",
        "        try:\n",
        "            # Create a copy to avoid modifying original\n",
        "            features = df.copy()\n",
        "\n",
        "            # Drop non-feature columns\n",
        "            drop_columns = [\n",
        "                'TEAM_NAME', 'MATCHUP', 'WL', 'TEAM_ABBREVIATION',\n",
        "                'OPPONENT_ABBREV', 'HOME_TEAM', 'AWAY_TEAM'\n",
        "            ]\n",
        "            features = features.drop([col for col in drop_columns if col in features.columns], axis=1)\n",
        "\n",
        "            # Convert categorical variables to numeric\n",
        "            categorical_columns = ['TEAM_ID', 'OPPONENT_TEAM_ID', 'HOME_TEAM_ID', 'AWAY_TEAM_ID']\n",
        "            for col in categorical_columns:\n",
        "                if col in features.columns:\n",
        "                    features[col] = features[col].astype('category').cat.codes\n",
        "\n",
        "            # Create game importance features\n",
        "            features['is_division_game'] = (features['TEAM_ID'] // 10 == features['OPPONENT_TEAM_ID'] // 10).astype(int)\n",
        "            features['month_number'] = pd.to_datetime(features['GAME_DATE']).dt.month\n",
        "            features['is_playoff_month'] = (features['month_number'] >= 4).astype(int)\n",
        "\n",
        "            # Handle missing values\n",
        "            numeric_columns = features.select_dtypes(include=['float64', 'int64']).columns\n",
        "            for col in numeric_columns:\n",
        "                features[col] = features[col].fillna(features[col].mean())\n",
        "\n",
        "            # Create interaction features\n",
        "            features['pts_per_min'] = features['PTS'] / features['MIN']\n",
        "            features['ast_to_tov'] = features['AST'] / (features['TOV'] + 1)  # Add 1 to avoid division by zero\n",
        "            features['fg_efficiency'] = features['FG_PCT'] * features['FGA']\n",
        "\n",
        "            # Create relative performance metrics\n",
        "            for stat in ['PTS', 'REB', 'AST']:\n",
        "                if f'{stat}_avg_10' in features.columns:\n",
        "                    features[f'{stat}_rel_performance'] = features[stat] / features[f'{stat}_avg_10']\n",
        "\n",
        "            # Normalize certain features\n",
        "            features['normalized_plus_minus'] = features['PLUS_MINUS'] / features['MIN']\n",
        "            features['usage_rate'] = (features['FGA'] + 0.44 * features['FTA'] + features['TOV']) / features['MIN']\n",
        "\n",
        "            # Sort features by date for time-series consistency\n",
        "            if 'GAME_DATE' in features.columns:\n",
        "                features = features.sort_values('GAME_DATE')\n",
        "\n",
        "            # Remove any remaining non-numeric columns except GAME_DATE and WIN\n",
        "            non_numeric_cols = features.select_dtypes(exclude=['float64', 'int64']).columns\n",
        "            keep_cols = ['GAME_DATE', 'WIN']\n",
        "            drop_cols = [col for col in non_numeric_cols if col not in keep_cols]\n",
        "            features = features.drop(drop_cols, axis=1)\n",
        "\n",
        "            return features\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in prepare_features: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "\n",
        "    def preprocess_game_data(self, df):\n",
        "        \"\"\"Preprocess the raw game data with improved NaN handling.\"\"\"\n",
        "        try:\n",
        "            logging.info(f\"Initial data shape: {df.shape}\")\n",
        "            logging.info(f\"Initial columns: {df.columns}\")\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # Create WIN column from WL\n",
        "            if 'WL' in df.columns:\n",
        "                df['WIN'] = df['WL'].apply(lambda x: 1 if x == 'W' else 0)\n",
        "                logging.info(\"Created WIN column from WL\")\n",
        "            else:\n",
        "                logging.error(\"WL column not found in data\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            # Convert GAME_DATE to datetime\n",
        "            df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n",
        "            logging.info(f\"After date conversion shape: {df.shape}\")\n",
        "\n",
        "            # Sort data\n",
        "            df = df.sort_values(['TEAM_ID', 'GAME_DATE'])\n",
        "\n",
        "            # Map team abbreviations\n",
        "            from nba_api.stats.static import teams\n",
        "            nba_teams = teams.get_teams()\n",
        "            team_abbrev_to_id = {team['abbreviation']: team['id'] for team in nba_teams}\n",
        "            team_id_to_abbrev = {team['id']: team['abbreviation'] for team in nba_teams}\n",
        "\n",
        "            df['TEAM_ABBREVIATION'] = df['TEAM_ID'].map(team_id_to_abbrev)\n",
        "            logging.info(f\"After team abbreviation mapping shape: {df.shape}\")\n",
        "\n",
        "            # Handle home/away determination\n",
        "            df['HOME_AWAY'] = df['MATCHUP'].apply(lambda x: 'HOME' if 'vs.' in x else 'AWAY')\n",
        "            df['OPPONENT_ABBREV'] = df['MATCHUP'].apply(lambda x: x.split(' ')[-1])\n",
        "\n",
        "            # Create HOME_TEAM and AWAY_TEAM columns\n",
        "            def get_home_team(row):\n",
        "                return row['TEAM_ABBREVIATION'] if row['HOME_AWAY'] == 'HOME' else row['OPPONENT_ABBREV']\n",
        "\n",
        "            def get_away_team(row):\n",
        "                return row['TEAM_ABBREVIATION'] if row['HOME_AWAY'] == 'AWAY' else row['OPPONENT_ABBREV']\n",
        "\n",
        "            df['HOME_TEAM'] = df.apply(get_home_team, axis=1)\n",
        "            df['AWAY_TEAM'] = df.apply(get_away_team, axis=1)\n",
        "\n",
        "            # Map team IDs\n",
        "            df['OPPONENT_TEAM_ID'] = df['OPPONENT_ABBREV'].map(team_abbrev_to_id)\n",
        "            df['HOME_TEAM_ID'] = df['HOME_TEAM'].map(team_abbrev_to_id)\n",
        "            df['AWAY_TEAM_ID'] = df['AWAY_TEAM'].map(team_abbrev_to_id)\n",
        "\n",
        "            # Handle missing opponent team IDs\n",
        "            missing_opponents = df[df['OPPONENT_TEAM_ID'].isna()]['OPPONENT_ABBREV'].unique()\n",
        "            if len(missing_opponents) > 0:\n",
        "                logging.warning(f\"Missing opponent team IDs for: {missing_opponents}\")\n",
        "\n",
        "            # Drop rows with missing opponent team IDs\n",
        "            df = df.dropna(subset=['OPPONENT_TEAM_ID'])\n",
        "            logging.info(f\"After dropping missing opponents shape: {df.shape}\")\n",
        "\n",
        "            # Fill missing values in numeric columns\n",
        "            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "            for col in numeric_cols:\n",
        "                df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "            # Convert IDs to integers with proper NaN handling\n",
        "            id_columns = ['TEAM_ID', 'OPPONENT_TEAM_ID', 'HOME_TEAM_ID', 'AWAY_TEAM_ID']\n",
        "            for col in id_columns:\n",
        "                df[col] = df[col].astype('float').fillna(-1).astype(int)\n",
        "\n",
        "            # Add features\n",
        "            logging.info(\"Adding fatigue features...\")\n",
        "            df = self.add_fatigue_features(df)\n",
        "\n",
        "            logging.info(\"Adding advanced features...\")\n",
        "            df = self.add_advanced_features(df)\n",
        "\n",
        "            logging.info(\"Adding rolling stats...\")\n",
        "            for window in self.config.ROLLING_WINDOWS:\n",
        "                df = self.add_rolling_stats(df, window)\n",
        "\n",
        "            logging.info(\"Adding head-to-head features...\")\n",
        "            df = self.add_head_to_head_features(df)\n",
        "\n",
        "            logging.info(\"Adding streak features...\")\n",
        "            df = self.add_streak_features(df)\n",
        "\n",
        "            logging.info(\"Adding time-based features...\")\n",
        "            df = self.add_time_based_features(df)\n",
        "\n",
        "            # Final NaN check and handling\n",
        "            df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "            logging.info(f\"Final shape: {df.shape}\")\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in preprocess_game_data: {str(e)}\")\n",
        "            import traceback\n",
        "            logging.error(traceback.format_exc())\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def add_advanced_features(self, df):\n",
        "        \"\"\"Add advanced statistical features.\"\"\"\n",
        "        try:\n",
        "            # Create a boolean for home games\n",
        "            df['is_home_game'] = df['HOME_AWAY'] == 'HOME'\n",
        "\n",
        "            # Create separate DataFrames for home and away games\n",
        "            home_games = df[df['is_home_game']].copy()\n",
        "            away_games = df[~df['is_home_game']].copy()\n",
        "\n",
        "            # Initialize columns with zeros\n",
        "            df['home_win_rate'] = 0.0\n",
        "            df['away_win_rate'] = 0.0\n",
        "\n",
        "            # Calculate win rates separately for home and away games\n",
        "            for team_id in df['TEAM_ID'].unique():\n",
        "                # Home win rate\n",
        "                team_home = home_games[home_games['TEAM_ID'] == team_id]\n",
        "                if not team_home.empty:\n",
        "                    win_rate = team_home['WIN'].rolling(10, min_periods=1).mean()\n",
        "                    df.loc[team_home.index, 'home_win_rate'] = win_rate\n",
        "\n",
        "                # Away win rate\n",
        "                team_away = away_games[away_games['TEAM_ID'] == team_id]\n",
        "                if not team_away.empty:\n",
        "                    win_rate = team_away['WIN'].rolling(10, min_periods=1).mean()\n",
        "                    df.loc[team_away.index, 'away_win_rate'] = win_rate\n",
        "\n",
        "            # Fill any remaining NaN values\n",
        "            df['home_win_rate'] = df['home_win_rate'].fillna(0.5)\n",
        "            df['away_win_rate'] = df['away_win_rate'].fillna(0.5)\n",
        "\n",
        "            # Difference between home and away win rates\n",
        "            df['home_road_diff'] = df['home_win_rate'] - df['away_win_rate']\n",
        "\n",
        "            # Head-to-head performance with minimum periods=1\n",
        "            df['h2h_wins'] = df.groupby(['TEAM_ID', 'OPPONENT_TEAM_ID'])['WIN'].transform(\n",
        "                lambda x: x.rolling(window=5, min_periods=1).mean().fillna(0.5)\n",
        "            )\n",
        "\n",
        "            # Recent form and trends with minimum periods=1\n",
        "            df['recent_form'] = df.groupby('TEAM_ID')['WIN'].transform(\n",
        "                lambda x: x.rolling(window=10, min_periods=1).mean().fillna(0.5)\n",
        "            )\n",
        "\n",
        "            df['pts_diff_trend'] = df.groupby('TEAM_ID')['PLUS_MINUS'].transform(\n",
        "                lambda x: x.rolling(window=5, min_periods=1).mean().fillna(0)\n",
        "            )\n",
        "\n",
        "            # Offensive and defensive ratings with minimum periods=1\n",
        "            df['off_rating'] = df.groupby('TEAM_ID')['PTS'].transform(\n",
        "                lambda x: x.rolling(window=5, min_periods=1).mean().fillna(x.mean())\n",
        "            )\n",
        "\n",
        "            df['def_rating'] = df.groupby('OPPONENT_TEAM_ID')['PTS'].transform(\n",
        "                lambda x: x.rolling(window=5, min_periods=1).mean().fillna(x.mean())\n",
        "            )\n",
        "\n",
        "            # Scoring consistency with minimum periods=1\n",
        "            df['scoring_consistency'] = df.groupby('TEAM_ID')['PTS'].transform(\n",
        "                lambda x: x.rolling(window=5, min_periods=1).std().fillna(0)\n",
        "            )\n",
        "\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in add_advanced_features: {str(e)}\")\n",
        "            return df\n",
        "\n",
        "\n",
        "    def add_rolling_stats(self, df, window):\n",
        "        \"\"\"Add rolling statistics for a given window size.\"\"\"\n",
        "        try:\n",
        "            stats_columns = ['PTS', 'REB', 'AST', 'PLUS_MINUS', 'FG_PCT', 'FT_PCT', 'FG3_PCT']\n",
        "\n",
        "            for col in stats_columns:\n",
        "                # Calculate rolling statistics with min_periods=1\n",
        "                df[f'{col}_avg_{window}'] = df.groupby('TEAM_ID')[col].transform(\n",
        "                    lambda x: x.rolling(window=window, min_periods=1).mean().fillna(x.mean())\n",
        "                )\n",
        "\n",
        "                df[f'{col}_std_{window}'] = df.groupby('TEAM_ID')[col].transform(\n",
        "                    lambda x: x.rolling(window=window, min_periods=1).std().fillna(0)\n",
        "                )\n",
        "\n",
        "                df[f'{col}_max_{window}'] = df.groupby('TEAM_ID')[col].transform(\n",
        "                    lambda x: x.rolling(window=window, min_periods=1).max().fillna(x.mean())\n",
        "                )\n",
        "\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in add_rolling_stats: {str(e)}\")\n",
        "            return df\n",
        "\n",
        "\n",
        "    def add_head_to_head_features(self, df):\n",
        "        \"\"\"Add head-to-head matchup features.\"\"\"\n",
        "        try:\n",
        "            # Calculate h2h win rate with minimum periods=1 and fill NaN with 0.5\n",
        "            df['h2h_win_rate'] = df.groupby(['TEAM_ID', 'OPPONENT_TEAM_ID'])['WIN'].transform(\n",
        "                lambda x: x.rolling(window=self.config.HEAD_TO_HEAD_WINDOW, min_periods=1).mean().fillna(0.5)\n",
        "            )\n",
        "\n",
        "            # Calculate point differential with minimum periods=1 and fill NaN with 0\n",
        "            df['h2h_point_diff'] = df.groupby(['TEAM_ID', 'OPPONENT_TEAM_ID'])['PLUS_MINUS'].transform(\n",
        "                lambda x: x.rolling(window=self.config.HEAD_TO_HEAD_WINDOW, min_periods=1).mean().fillna(0)\n",
        "            )\n",
        "\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in add_head_to_head_features: {str(e)}\")\n",
        "            return df\n",
        "\n",
        "    def add_fatigue_features(self, df):\n",
        "        \"\"\"Add fatigue and travel-related features.\"\"\"\n",
        "        # Ensure dates are in datetime format (redundant safety check)\n",
        "        if not pd.api.types.is_datetime64_any_dtype(df['GAME_DATE']):\n",
        "            df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n",
        "\n",
        "        # Sort by team and date\n",
        "        df = df.sort_values(['TEAM_ID', 'GAME_DATE']).copy()\n",
        "\n",
        "        # Calculate days between games\n",
        "        df['days_since_last'] = df.groupby('TEAM_ID')['GAME_DATE'].diff().dt.days.fillna(0)\n",
        "\n",
        "        # Calculate games in last 7 days using vectorized operations\n",
        "        def calculate_rolling_games(group):\n",
        "            # Create a Series with the game dates\n",
        "            dates = pd.Series(group['GAME_DATE'])\n",
        "            counts = []\n",
        "\n",
        "            for current_date in dates:\n",
        "                # Count games in previous 7 days (excluding current game)\n",
        "                count = ((dates < current_date) &\n",
        "                        (dates >= current_date - pd.Timedelta(days=7))).sum()\n",
        "                counts.append(count)\n",
        "\n",
        "            return counts\n",
        "\n",
        "        # Apply the calculation to each team\n",
        "        df['games_last_7d'] = df.groupby('TEAM_ID').apply(\n",
        "            calculate_rolling_games\n",
        "        ).explode().values\n",
        "\n",
        "        # Calculate back-to-back games\n",
        "        df['is_back_to_back'] = (df['days_since_last'] == 1).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def add_streak_features(self, df):\n",
        "        \"\"\"Add streak-related features.\"\"\"\n",
        "        try:\n",
        "            def get_streak(series):\n",
        "                streak = 0\n",
        "                streaks = []\n",
        "                for val in series:\n",
        "                    if val == 1:\n",
        "                        streak = streak + 1 if streak >= 0 else 1\n",
        "                    else:\n",
        "                        streak = streak - 1 if streak <= 0 else -1\n",
        "                    streaks.append(streak)\n",
        "                return pd.Series(streaks, index=series.index)\n",
        "\n",
        "            # Calculate streaks\n",
        "            df['streak'] = df.groupby('TEAM_ID')['WIN'].transform(\n",
        "                lambda x: get_streak(x)\n",
        "            )\n",
        "\n",
        "            # Calculate momentum with minimum periods=1\n",
        "            weights = np.array([0.35, 0.25, 0.20, 0.15, 0.05])\n",
        "            def weighted_momentum(series):\n",
        "                return series.rolling(5, min_periods=1).apply(\n",
        "                    lambda x: np.sum(weights[-len(x):] * x) / np.sum(weights[-len(x):])\n",
        "                ).fillna(0.5)\n",
        "\n",
        "            df['momentum'] = df.groupby('TEAM_ID')['WIN'].transform(weighted_momentum)\n",
        "\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in add_streak_features: {str(e)}\")\n",
        "            return df\n",
        "\n",
        "    def add_time_based_features(self, df):\n",
        "        \"\"\"Add time-based features such as season phase and rest days.\"\"\"\n",
        "        try:\n",
        "            logging.info(\"Starting add_time_based_features\")\n",
        "            logging.info(f\"Initial shape: {df.shape}\")\n",
        "\n",
        "            # Season phase (regular season or playoffs)\n",
        "            df['month'] = df['GAME_DATE'].dt.month\n",
        "            df['season_phase'] = df['month'].apply(\n",
        "                lambda x: 'playoffs' if x >= 4 else 'regular'\n",
        "            )\n",
        "\n",
        "            # Encode season phase\n",
        "            le = LabelEncoder()\n",
        "            df['season_phase'] = le.fit_transform(df['season_phase'])\n",
        "\n",
        "            # Rest days between games\n",
        "            df['rest_days'] = df.groupby('TEAM_ID')['GAME_DATE'].diff().dt.days.fillna(0)\n",
        "\n",
        "            logging.info(f\"Final shape after time-based features: {df.shape}\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in add_time_based_features: {str(e)}\")\n",
        "            return df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PRy8fYUqf96A",
        "outputId": "404d8f45-2c62-4c46-df9b-0d05f50d8a5a"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting script execution...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(self):\n",
        "        self.config = NotebookConfig()\n",
        "        self.scaler = StandardScaler()\n",
        "        self.imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "    def evaluate_model(self, model, X_test, y_test, model_name):\n",
        "        \"\"\"Evaluate model with proper error handling.\"\"\"\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "                y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "            else:\n",
        "                y_pred = model.predict(X_test)\n",
        "                y_pred = (y_pred > 0.5).astype(int)\n",
        "                y_pred_proba = y_pred\n",
        "\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred)\n",
        "            roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "            precision = precision_score(y_test, y_pred)\n",
        "            recall = recall_score(y_test, y_pred)\n",
        "\n",
        "            logging.info(f\"{model_name} Evaluation:\")\n",
        "            logging.info(f\"  Accuracy: {acc:.4f}\")\n",
        "            logging.info(f\"  F1 Score: {f1:.4f}\")\n",
        "            logging.info(f\"  ROC AUC: {roc_auc:.4f}\")\n",
        "            logging.info(f\"  Precision: {precision:.4f}\")\n",
        "            logging.info(f\"  Recall: {recall:.4f}\")\n",
        "\n",
        "            cm = confusion_matrix(y_test, y_pred)\n",
        "            logging.info(f\"  Confusion Matrix:\")\n",
        "            logging.info(f\"    TN: {cm[0,0]}, FP: {cm[0,1]}\")\n",
        "            logging.info(f\"    FN: {cm[1,0]}, TP: {cm[1,1]}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error evaluating {model_name}: {str(e)}\")\n",
        "\n",
        "    def preprocess_features(self, X_train, X_val, X_test):\n",
        "        \"\"\"Preprocess features with improved scaling and imputation.\"\"\"\n",
        "        # Convert to DataFrame if not already\n",
        "        if not isinstance(X_train, pd.DataFrame):\n",
        "            X_train = pd.DataFrame(X_train)\n",
        "            X_val = pd.DataFrame(X_val)\n",
        "            X_test = pd.DataFrame(X_test)\n",
        "\n",
        "        feature_names = [f'feature_{i}' for i in range(X_train.shape[1])]\n",
        "        X_train.columns = feature_names\n",
        "        X_val.columns = feature_names\n",
        "        X_test.columns = feature_names\n",
        "\n",
        "        # First handle missing values\n",
        "        X_train_imputed = self.imputer.fit_transform(X_train)\n",
        "        X_val_imputed = self.imputer.transform(X_val)\n",
        "        X_test_imputed = self.imputer.transform(X_test)\n",
        "\n",
        "        # Then scale the data\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train_imputed)\n",
        "        X_val_scaled = self.scaler.transform(X_val_imputed)\n",
        "        X_test_scaled = self.scaler.transform(X_test_imputed)\n",
        "\n",
        "        # Convert back to DataFrame\n",
        "        X_train_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
        "        X_val_df = pd.DataFrame(X_val_scaled, columns=feature_names)\n",
        "        X_test_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
        "\n",
        "        return X_train_df, X_val_df, X_test_df\n",
        "\n",
        "    def train_baseline_model(self, X_train, y_train):\n",
        "        \"\"\"Train a more robust baseline model with balanced class weights.\"\"\"\n",
        "        model = LogisticRegression(\n",
        "            class_weight='balanced',\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            random_state=self.config.RANDOM_SEED,\n",
        "            max_iter=1000\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        return model\n",
        "\n",
        "    def optimize_xgboost_params(self, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"Optimize XGBoost with improved parameters.\"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'max_depth': trial.suggest_int('max_depth', 2, 6),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),\n",
        "                'gamma': trial.suggest_float('gamma', 0, 2),\n",
        "                'scale_pos_weight': sum(y_train == 0) / sum(y_train == 1),\n",
        "                'objective': 'binary:logistic',\n",
        "                'tree_method': 'exact',\n",
        "                'random_state': self.config.RANDOM_SEED,\n",
        "                'missing': np.nan  # Explicitly handle missing values\n",
        "            }\n",
        "\n",
        "            model = xgb.XGBClassifier(**params)\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict_proba(X_val)[:, 1]\n",
        "            return roc_auc_score(y_val, y_pred)\n",
        "\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(objective, n_trials=20)\n",
        "\n",
        "        return study.best_params\n",
        "\n",
        "    def optimize_lightgbm_params(self, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"Optimize LightGBM with improved parameters.\"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'num_leaves': trial.suggest_int('num_leaves', 8, 32),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),\n",
        "                'objective': 'binary',\n",
        "                'metric': 'auc',\n",
        "                'deterministic': True,\n",
        "                'force_row_wise': True,\n",
        "                'min_data_in_leaf': 20,\n",
        "                'scale_pos_weight': sum(y_train == 0) / sum(y_train == 1),\n",
        "                'random_state': self.config.RANDOM_SEED\n",
        "            }\n",
        "\n",
        "            model = lgb.LGBMClassifier(**params)\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict_proba(X_val)[:, 1]\n",
        "            return roc_auc_score(y_val, y_pred)\n",
        "\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(objective, n_trials=20)\n",
        "\n",
        "        return study.best_params\n",
        "\n",
        "    def create_neural_network(self, input_dim):\n",
        "        \"\"\"Create a neural network with proper input dimension handling.\"\"\"\n",
        "        try:\n",
        "            if input_dim <= 0:\n",
        "                raise ValueError(f\"Invalid input dimension: {input_dim}\")\n",
        "\n",
        "            model = Sequential([\n",
        "                Dense(64, input_shape=(input_dim,), activation='relu',\n",
        "                      kernel_regularizer=l2(0.01)),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.3),\n",
        "\n",
        "                Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.2),\n",
        "\n",
        "                Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.1),\n",
        "\n",
        "                Dense(1, activation='sigmoid')\n",
        "            ])\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=Adam(learning_rate=0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy']\n",
        "            )\n",
        "\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error creating neural network: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def train_models(self, X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "        \"\"\"Train all models with improved error handling and class weight calculation.\"\"\"\n",
        "        try:\n",
        "            logging.info(\"Preprocessing features...\")\n",
        "\n",
        "            # Validate input data\n",
        "            if X_train.shape[0] == 0 or X_train.shape[1] == 0:\n",
        "                raise ValueError(f\"Invalid training data shape: {X_train.shape}\")\n",
        "\n",
        "            # Preprocess the data\n",
        "            X_train_processed, X_val_processed, X_test_processed = self.preprocess_features(\n",
        "                X_train, X_val, X_test\n",
        "            )\n",
        "\n",
        "            # Convert targets to proper format and numpy arrays\n",
        "            y_train = y_train.astype(int).values\n",
        "            y_val = y_val.astype(int).values\n",
        "            y_test = y_test.astype(int).values\n",
        "\n",
        "            # Initialize models list\n",
        "            trained_models = []\n",
        "\n",
        "            # Train baseline model\n",
        "            logging.info(\"Training baseline Logistic Regression model...\")\n",
        "            baseline_model = self.train_baseline_model(X_train_processed, y_train)\n",
        "            trained_models.append(baseline_model)\n",
        "            self.evaluate_model(baseline_model, X_test_processed, y_test, \"Baseline Logistic Regression\")\n",
        "\n",
        "            # Train XGBoost\n",
        "            logging.info(\"Training XGBoost model...\")\n",
        "            xgb_params = self.optimize_xgboost_params(X_train_processed, y_train, X_val_processed, y_val)\n",
        "            xgb_model = xgb.XGBClassifier(**xgb_params)\n",
        "            xgb_model.fit(X_train_processed, y_train)\n",
        "            trained_models.append(xgb_model)\n",
        "            self.evaluate_model(xgb_model, X_test_processed, y_test, \"XGBoost\")\n",
        "\n",
        "            # Train LightGBM\n",
        "            logging.info(\"Training LightGBM model...\")\n",
        "            lgb_params = self.optimize_lightgbm_params(X_train_processed, y_train, X_val_processed, y_val)\n",
        "            lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
        "            lgb_model.fit(X_train_processed, y_train)\n",
        "            trained_models.append(lgb_model)\n",
        "            self.evaluate_model(lgb_model, X_test_processed, y_test, \"LightGBM\")\n",
        "\n",
        "            # Train Neural Network\n",
        "            logging.info(\"Training Neural Network model...\")\n",
        "            input_dim = X_train_processed.shape[1]\n",
        "            if input_dim <= 0:\n",
        "                raise ValueError(f\"Invalid input dimension for neural network: {input_dim}\")\n",
        "\n",
        "            logging.info(f\"Creating neural network with input dimension: {input_dim}\")\n",
        "            nn_model = self.create_neural_network(input_dim)\n",
        "\n",
        "            # Calculate class weights properly using numpy\n",
        "            n_negative = np.sum(y_train == 0)\n",
        "            n_positive = np.sum(y_train == 1)\n",
        "            class_weights = {\n",
        "                0: 1.0,\n",
        "                1: (n_negative / n_positive) if n_positive > 0 else 1.0\n",
        "            }\n",
        "\n",
        "            callbacks = [\n",
        "                EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001)\n",
        "            ]\n",
        "\n",
        "            nn_model.fit(\n",
        "                X_train_processed, y_train,\n",
        "                validation_data=(X_val_processed, y_val),\n",
        "                epochs=200,\n",
        "                batch_size=32,\n",
        "                callbacks=callbacks,\n",
        "                class_weight=class_weights,\n",
        "                verbose=1\n",
        "            )\n",
        "            trained_models.append(nn_model)\n",
        "            self.evaluate_model(nn_model, X_test_processed, y_test, \"Neural Network\")\n",
        "\n",
        "            return trained_models\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in train_models: {str(e)}\")\n",
        "            logging.error(f\"Error details - X_train shape: {X_train.shape if hasattr(X_train, 'shape') else 'No shape'}\")\n",
        "            logging.error(f\"Stack trace: {traceback.format_exc()}\")\n",
        "            raise"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vQQj6vsigF3H"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Game Predictor Class\n",
        "# This class handles making predictions using the trained models.\n",
        "\n",
        "class GamePredictor:\n",
        "    def __init__(self, models, scaler, processor):\n",
        "        self.baseline_model, self.xgb_model, self.lgb_model, self.nn_model = models\n",
        "        self.scaler = scaler\n",
        "        self.processor = processor\n",
        "        self.config = NotebookConfig()\n",
        "\n",
        "        # Cache team data\n",
        "        self.nba_teams = teams.get_teams()\n",
        "        self.team_abbrev_to_id = {team['abbreviation']: team['id'] for team in self.nba_teams}\n",
        "\n",
        "        # Define core feature columns\n",
        "        self.core_features = [\n",
        "            'FG_PCT', 'FG3_PCT', 'FT_PCT', 'AST',\n",
        "            'REB', 'TOV', 'PLUS_MINUS', 'pts_per_min',\n",
        "            'ast_to_tov', 'fg_efficiency'\n",
        "        ]\n",
        "\n",
        "    def prepare_sample_game_data(self, team_abbrev, opponent_abbrev, game_date=None, is_home=True):\n",
        "        \"\"\"Create properly formatted sample game data.\"\"\"\n",
        "        if game_date is None:\n",
        "            game_date = datetime.now()\n",
        "\n",
        "        # Get team IDs\n",
        "        team_id = self.team_abbrev_to_id.get(team_abbrev)\n",
        "        opponent_id = self.team_abbrev_to_id.get(opponent_abbrev)\n",
        "\n",
        "        if not team_id or not opponent_id:\n",
        "            raise ValueError(f\"Invalid team abbreviation: {team_abbrev if not team_id else opponent_abbrev}\")\n",
        "\n",
        "        # Create matchup string\n",
        "        matchup = f\"{team_abbrev} vs. {opponent_abbrev}\" if is_home else f\"{team_abbrev} @ {opponent_abbrev}\"\n",
        "\n",
        "        # Create sample game data with all required fields\n",
        "        sample_game = pd.DataFrame({\n",
        "            'GAME_DATE': [game_date],\n",
        "            'TEAM_ID': [team_id],\n",
        "            'TEAM_ABBREVIATION': [team_abbrev],\n",
        "            'TEAM_NAME': [next((team['full_name'] for team in self.nba_teams if team['id'] == team_id), '')],\n",
        "            'OPPONENT_TEAM_ID': [opponent_id],\n",
        "            'OPPONENT_ABBREV': [opponent_abbrev],\n",
        "            'MATCHUP': [matchup],\n",
        "            'WL': ['W'],  # Placeholder\n",
        "            'MIN': [240],  # Standard game length\n",
        "            'PTS': [100],  # Placeholder stats\n",
        "            'FGM': [40],\n",
        "            'FGA': [80],\n",
        "            'FG_PCT': [0.500],\n",
        "            'FG3M': [10],\n",
        "            'FG3A': [25],\n",
        "            'FG3_PCT': [0.400],\n",
        "            'FTM': [10],\n",
        "            'FTA': [15],\n",
        "            'FT_PCT': [0.667],\n",
        "            'OREB': [10],\n",
        "            'DREB': [30],\n",
        "            'REB': [40],\n",
        "            'AST': [25],\n",
        "            'STL': [8],\n",
        "            'BLK': [5],\n",
        "            'TOV': [12],\n",
        "            'PF': [20],\n",
        "            'PLUS_MINUS': [0]\n",
        "        })\n",
        "\n",
        "        return sample_game\n",
        "\n",
        "    def predict_game(self, team_abbrev, opponent_abbrev, game_date=None, is_home=True):\n",
        "        \"\"\"Make ensemble prediction for a single game.\"\"\"\n",
        "        try:\n",
        "            # Prepare properly formatted game data\n",
        "            game_data = self.prepare_sample_game_data(team_abbrev, opponent_abbrev, game_date, is_home)\n",
        "\n",
        "            # Process game data\n",
        "            processed_data = self.processor.preprocess_game_data(game_data)\n",
        "            if processed_data.empty:\n",
        "                raise ValueError(\"No valid processed data\")\n",
        "\n",
        "            # Calculate derived features\n",
        "            processed_data['pts_per_min'] = processed_data['PTS'] / processed_data['MIN']\n",
        "            processed_data['ast_to_tov'] = processed_data['AST'] / (processed_data['TOV'] + 1)\n",
        "            processed_data['fg_efficiency'] = processed_data['FG_PCT'] * processed_data['FGA']\n",
        "\n",
        "            # Select only the core features used in training\n",
        "            X = processed_data[self.core_features]\n",
        "\n",
        "            # Scale features\n",
        "            X_scaled = self.scaler.transform(X)\n",
        "\n",
        "            # Get predictions from each model\n",
        "            baseline_pred = self.baseline_model.predict_proba(X_scaled)[:, 1]\n",
        "            xgb_pred = self.xgb_model.predict_proba(X_scaled)[:, 1]\n",
        "            lgb_pred = self.lgb_model.predict_proba(X_scaled)[:, 1]\n",
        "            nn_pred = self.nn_model.predict(X_scaled).ravel()\n",
        "\n",
        "            # Ensemble prediction (weighted average)\n",
        "            weights = [0.2, 0.3, 0.3, 0.2]  # Adjustable weights for each model\n",
        "            ensemble_pred = (\n",
        "                weights[0] * baseline_pred +\n",
        "                weights[1] * xgb_pred +\n",
        "                weights[2] * lgb_pred +\n",
        "                weights[3] * nn_pred\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'prediction': float(ensemble_pred[0]),\n",
        "                'confidence': float(np.abs(ensemble_pred[0] - 0.5) * 2),\n",
        "                'model_predictions': {\n",
        "                    'baseline': float(baseline_pred[0]),\n",
        "                    'xgboost': float(xgb_pred[0]),\n",
        "                    'lightgbm': float(lgb_pred[0]),\n",
        "                    'neural_network': float(nn_pred[0])\n",
        "                }\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in predict_game: {str(e)}\")\n",
        "            raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R1yLqt6gNd3",
        "outputId": "7a605d6f-9a7c-4616-b928-e40c767376bc",
        "collapsed": true
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 19:16:43,909 - INFO - Initial data shape: (1, 28)\n",
            "2024-11-13 19:16:43,912 - INFO - Initial columns: Index(['GAME_DATE', 'TEAM_ID', 'TEAM_ABBREVIATION', 'TEAM_NAME',\n",
            "       'OPPONENT_TEAM_ID', 'OPPONENT_ABBREV', 'MATCHUP', 'WL', 'MIN', 'PTS',\n",
            "       'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA',\n",
            "       'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
            "       'PLUS_MINUS'],\n",
            "      dtype='object')\n",
            "2024-11-13 19:16:43,917 - INFO - Created WIN column from WL\n",
            "2024-11-13 19:16:43,920 - INFO - After date conversion shape: (1, 29)\n",
            "2024-11-13 19:16:43,931 - INFO - After team abbreviation mapping shape: (1, 29)\n",
            "2024-11-13 19:16:43,947 - INFO - After dropping missing opponents shape: (1, 34)\n",
            "2024-11-13 19:16:43,964 - INFO - Adding fatigue features...\n",
            "2024-11-13 19:16:43,978 - INFO - Adding advanced features...\n",
            "2024-11-13 19:16:44,001 - INFO - Adding rolling stats...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 57, number of negative: 43\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 350\n",
            "[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.570000 -> initscore=0.281851\n",
            "[LightGBM] [Info] Start training from score 0.281851\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 19:16:44,140 - INFO - Adding head-to-head features...\n",
            "2024-11-13 19:16:44,149 - INFO - Adding streak features...\n",
            "2024-11-13 19:16:44,159 - INFO - Adding time-based features...\n",
            "2024-11-13 19:16:44,161 - INFO - Starting add_time_based_features\n",
            "2024-11-13 19:16:44,164 - INFO - Initial shape: (1, 114)\n",
            "2024-11-13 19:16:44,172 - INFO - Final shape after time-based features: (1, 117)\n",
            "2024-11-13 19:16:44,192 - INFO - Final shape: (1, 117)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 19:16:44,369 - INFO - GamePredictor test passed. Prediction: {'prediction': 0.5901043924233957, 'confidence': 0.18020878484679148, 'model_predictions': {'baseline': 1.0, 'xgboost': 0.5150402784347534, 'lightgbm': 0.11864098990680226, 'neural_network': 1.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: FastAPI Setup\n",
        "# Setting up a local FastAPI application for making predictions via API.\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class GameData(BaseModel):\n",
        "    TEAM_ABBREVIATION: str\n",
        "    OPPONENT_ABBREV: str\n",
        "    GAME_DATE: str  # Date in 'YYYY-MM-DD' format\n",
        "    MATCHUP: str\n",
        "    WL: str  # Placeholder\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict_game_endpoint(game_data: GameData):\n",
        "    \"\"\"API endpoint for predicting a game's outcome.\"\"\"\n",
        "    try:\n",
        "        input_df = pd.DataFrame([game_data.dict()])\n",
        "        predictor = GamePredictor(models, scaler, processor)\n",
        "        prediction = predictor.predict_game(input_df)\n",
        "        return prediction\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}"
      ],
      "metadata": {
        "id": "jWnSPs0hgPnW"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Interactive Interface\n",
        "# Creating an interactive widget interface for making predictions in the notebook.\n",
        "\n",
        "def get_valid_team_abbreviations():\n",
        "    \"\"\"Get list of valid NBA team abbreviations.\"\"\"\n",
        "    return [\n",
        "        'ATL', 'BOS', 'BKN', 'CHA', 'CHI', 'CLE', 'DAL', 'DEN', 'DET', 'GSW',\n",
        "        'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NOP', 'NYK',\n",
        "        'OKC', 'ORL', 'PHI', 'PHX', 'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS'\n",
        "    ]\n",
        "\n",
        "def validate_team_abbreviation(abbrev):\n",
        "    \"\"\"Validate team abbreviation.\"\"\"\n",
        "    valid_teams = get_valid_team_abbreviations()\n",
        "    if abbrev not in valid_teams:\n",
        "        raise ValueError(\n",
        "            f\"Invalid team abbreviation: {abbrev}\\n\"\n",
        "            f\"Valid abbreviations are: {', '.join(valid_teams)}\"\n",
        "        )\n",
        "    return True\n",
        "\n",
        "class ModelManager:\n",
        "    def __init__(self):\n",
        "        self.config = NotebookConfig()\n",
        "        self.data_manager = DataManager()\n",
        "        self.processor = DataProcessor()\n",
        "        self.trainer = ModelTrainer()\n",
        "\n",
        "    def train_and_save_models(self):\n",
        "        \"\"\"Train and save all models.\"\"\"\n",
        "        try:\n",
        "            # Fetch and process data\n",
        "            logging.info(\"Fetching NBA data...\")\n",
        "            game_data = fetch_or_load_data()\n",
        "            if game_data.empty:\n",
        "                raise ValueError(\"No game data available.\")\n",
        "\n",
        "            # Preprocess data\n",
        "            logging.info(\"Preprocessing game data...\")\n",
        "            processed_data = self.processor.preprocess_game_data(game_data)\n",
        "\n",
        "            # Calculate core features\n",
        "            processed_data['pts_per_min'] = processed_data['PTS'] / processed_data['MIN']\n",
        "            processed_data['ast_to_tov'] = processed_data['AST'] / (processed_data['TOV'] + 1)\n",
        "            processed_data['fg_efficiency'] = processed_data['FG_PCT'] * processed_data['FGA']\n",
        "\n",
        "            # Select core features\n",
        "            core_features = [\n",
        "                'FG_PCT', 'FG3_PCT', 'FT_PCT', 'AST',\n",
        "                'REB', 'TOV', 'PLUS_MINUS', 'pts_per_min',\n",
        "                'ast_to_tov', 'fg_efficiency'\n",
        "            ]\n",
        "\n",
        "            X = processed_data[core_features]\n",
        "            y = processed_data['WIN']\n",
        "\n",
        "            # Split data\n",
        "            train_size = int(0.7 * len(X))\n",
        "            val_size = int(0.15 * len(X))\n",
        "\n",
        "            X_train = X[:train_size]\n",
        "            y_train = y[:train_size]\n",
        "            X_val = X[train_size:train_size + val_size]\n",
        "            y_val = y[train_size:train_size + val_size]\n",
        "            X_test = X[train_size + val_size:]\n",
        "            y_test = y[train_size + val_size:]\n",
        "\n",
        "            # Train models\n",
        "            logging.info(\"Training models...\")\n",
        "            models = self.trainer.train_models(X_train, X_val, X_test, y_train, y_val, y_test)\n",
        "            scaler = self.trainer.scaler\n",
        "\n",
        "            # Save models\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            self.save_models(models, scaler, timestamp)\n",
        "\n",
        "            return models, scaler\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in train_and_save_models: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def save_models(self, models, scaler, timestamp):\n",
        "        \"\"\"Save all models and scaler.\"\"\"\n",
        "        try:\n",
        "            # Create models directory if it doesn't exist\n",
        "            os.makedirs(self.config.MODELS_DIR, exist_ok=True)\n",
        "\n",
        "            # Save individual models\n",
        "            logging.info(\"Saving baseline model...\")\n",
        "            joblib.dump(models[0], f'{self.config.MODELS_DIR}/baseline_model_{timestamp}.joblib')\n",
        "\n",
        "            logging.info(\"Saving XGBoost model...\")\n",
        "            models[1].save_model(f'{self.config.MODELS_DIR}/xgb_model_{timestamp}.json')\n",
        "\n",
        "            logging.info(\"Saving LightGBM model...\")\n",
        "            # Save LightGBM model directly using the booster\n",
        "            if hasattr(models[2], '_Booster'):\n",
        "                models[2]._Booster.save_model(f'{self.config.MODELS_DIR}/lgb_model_{timestamp}.txt')\n",
        "            else:\n",
        "                models[2].booster_.save_model(f'{self.config.MODELS_DIR}/lgb_model_{timestamp}.txt')\n",
        "\n",
        "            logging.info(\"Saving Neural Network model...\")\n",
        "            models[3].save(f'{self.config.MODELS_DIR}/nn_model_{timestamp}.keras')\n",
        "\n",
        "            logging.info(\"Saving scaler...\")\n",
        "            with open(f'{self.config.MODELS_DIR}/scaler_{timestamp}.pkl', 'wb') as f:\n",
        "                pickle.dump(scaler, f)\n",
        "\n",
        "            logging.info(f\"Models saved with timestamp: {timestamp}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error saving models: {str(e)}\")\n",
        "            logging.error(f\"Full error: {traceback.format_exc()}\")\n",
        "            raise\n",
        "\n",
        "    def load_most_recent_models(self):\n",
        "        \"\"\"Load the most recently saved models.\"\"\"\n",
        "        try:\n",
        "            models_dir = Path(self.config.MODELS_DIR)\n",
        "            if not models_dir.exists():\n",
        "                logging.info(f\"Models directory not found: {models_dir}\")\n",
        "                return\n",
        "\n",
        "            # Get all model files\n",
        "            model_files = list(models_dir.glob(\"baseline_model_*.joblib\"))\n",
        "            if not model_files:\n",
        "                logging.info(\"No model files found\")\n",
        "                return\n",
        "\n",
        "            # Extract timestamps and get the most recent one\n",
        "            timestamps = []\n",
        "            for file in model_files:\n",
        "                try:\n",
        "                    timestamp = file.stem.split('baseline_model_')[1]\n",
        "                    timestamps.append(timestamp)\n",
        "                except Exception as e:\n",
        "                    logging.warning(f\"Couldn't parse timestamp from file: {file}\")\n",
        "                    continue\n",
        "\n",
        "            if not timestamps:\n",
        "                logging.info(\"No valid timestamps found\")\n",
        "                return\n",
        "\n",
        "            latest_timestamp = max(timestamps)\n",
        "            logging.info(f\"Found latest timestamp: {latest_timestamp}\")\n",
        "\n",
        "            # Construct full paths for all model files\n",
        "            baseline_path = models_dir / f\"baseline_model_{latest_timestamp}.joblib\"\n",
        "            xgb_path = models_dir / f\"xgb_model_{latest_timestamp}.json\"\n",
        "            lgb_path = models_dir / f\"lgb_model_{latest_timestamp}.txt\"\n",
        "            nn_path = models_dir / f\"nn_model_{latest_timestamp}.keras\"\n",
        "            scaler_path = models_dir / f\"scaler_{latest_timestamp}.pkl\"\n",
        "\n",
        "            # Verify all files exist\n",
        "            required_files = [baseline_path, xgb_path, lgb_path, nn_path, scaler_path]\n",
        "            for file in required_files:\n",
        "                if not file.exists():\n",
        "                    logging.error(f\"Required model file not found: {file}\")\n",
        "                    return\n",
        "\n",
        "            # Load models\n",
        "            models = []\n",
        "\n",
        "            # Load baseline model\n",
        "            logging.info(\"Loading baseline model...\")\n",
        "            models.append(joblib.load(baseline_path))\n",
        "\n",
        "            # Load XGBoost model\n",
        "            logging.info(\"Loading XGBoost model...\")\n",
        "            xgb_model = xgb.XGBClassifier()\n",
        "            xgb_model.load_model(str(xgb_path))\n",
        "            models.append(xgb_model)\n",
        "\n",
        "            # Load LightGBM model\n",
        "            logging.info(\"Loading LightGBM model...\")\n",
        "            booster = lgb.Booster(model_file=str(lgb_path))\n",
        "            lgb_model = lgb.LGBMClassifier(n_estimators=100)  # Initialize with default params\n",
        "            lgb_model._Booster = booster  # Set the booster\n",
        "            lgb_model._n_features = booster.num_feature()  # Set number of features\n",
        "            lgb_model._n_classes = 2  # Binary classification\n",
        "            lgb_model._classes = np.array([0, 1])  # Binary classes\n",
        "            models.append(lgb_model)\n",
        "\n",
        "            # Load Neural Network model\n",
        "            logging.info(\"Loading Neural Network model...\")\n",
        "            nn_model = tf.keras.models.load_model(str(nn_path))\n",
        "            models.append(nn_model)\n",
        "\n",
        "            # Load scaler\n",
        "            logging.info(\"Loading scaler...\")\n",
        "            with open(scaler_path, 'rb') as f:\n",
        "                scaler = pickle.load(f)\n",
        "\n",
        "            self.models = models\n",
        "            self.scaler = scaler\n",
        "            logging.info(f\"Successfully loaded all models from timestamp: {latest_timestamp}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error loading models: {str(e)}\")\n",
        "            logging.error(f\"Full error: {traceback.format_exc()}\")\n",
        "            self.models = None\n",
        "            self.scaler = None\n",
        "\n",
        "    def predict_with_models(self, X):\n",
        "        \"\"\"Make predictions with all models.\"\"\"\n",
        "        if self.models is None or self.scaler is None:\n",
        "            raise ValueError(\"Models not loaded\")\n",
        "\n",
        "        # Scale the input data\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        predictions = []\n",
        "        for i, model in enumerate(self.models):\n",
        "            try:\n",
        "                if isinstance(model, lgb.LGBMClassifier):\n",
        "                    pred = model.predict_proba(X_scaled)[:, 1]\n",
        "                elif hasattr(model, 'predict_proba'):\n",
        "                    pred = model.predict_proba(X_scaled)[:, 1]\n",
        "                else:\n",
        "                    pred = model.predict(X_scaled).ravel()\n",
        "                predictions.append(pred)\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error predicting with model {i}: {str(e)}\")\n",
        "                raise\n",
        "\n",
        "        return np.mean(predictions, axis=0)\n",
        "\n",
        "def create_prediction_interface():\n",
        "    \"\"\"Create and display the prediction interface.\"\"\"\n",
        "    # Create widgets\n",
        "    home_team = widgets.Text(description='Home Team:', value='')\n",
        "    away_team = widgets.Text(description='Away Team:', value='')\n",
        "    train_button = widgets.Button(description='Train Models')\n",
        "    predict_button = widgets.Button(description='Predict')\n",
        "    output = widgets.Output()\n",
        "    status_label = widgets.HTML(value=\"\")  # Add status label\n",
        "\n",
        "    # Initialize prediction interface\n",
        "    interface = PredictionInterface()\n",
        "\n",
        "    def update_status():\n",
        "        \"\"\"Update status label based on model availability.\"\"\"\n",
        "        if interface.models is not None and interface.scaler is not None:\n",
        "            status_label.value = '<p style=\"color: green;\">Models loaded and ready</p>'\n",
        "        else:\n",
        "            status_label.value = '<p style=\"color: red;\">No models loaded - please train first</p>'\n",
        "\n",
        "    update_status()  # Initial status update\n",
        "\n",
        "    def on_train_button_clicked(b):\n",
        "        with output:\n",
        "            clear_output()\n",
        "            try:\n",
        "                model_manager = ModelManager()\n",
        "                print(\"Training models... This may take a few minutes.\")\n",
        "                interface.models, interface.scaler = model_manager.train_and_save_models()\n",
        "                print(\"Models trained and saved successfully!\")\n",
        "                update_status()\n",
        "            except Exception as e:\n",
        "                print(f\"Error training models: {str(e)}\")\n",
        "                logging.error(f\"Training error: {traceback.format_exc()}\")\n",
        "\n",
        "    def on_predict_button_clicked(b):\n",
        "        with output:\n",
        "            clear_output()\n",
        "            try:\n",
        "                if interface.models is None or interface.scaler is None:\n",
        "                    print(\"Please train models first!\")\n",
        "                    return\n",
        "\n",
        "                if not home_team.value or not away_team.value:\n",
        "                    print(\"Please enter both home and away teams!\")\n",
        "                    return\n",
        "\n",
        "                # Validate team abbreviations\n",
        "                home_abbrev = home_team.value.upper()\n",
        "                away_abbrev = away_team.value.upper()\n",
        "\n",
        "                try:\n",
        "                    validate_team_abbreviation(home_abbrev)\n",
        "                    validate_team_abbreviation(away_abbrev)\n",
        "                except ValueError as e:\n",
        "                    print(str(e))\n",
        "                    return\n",
        "\n",
        "                predictor = GamePredictor(interface.models, interface.scaler, interface.processor)\n",
        "                prediction = predictor.predict_game(\n",
        "                    team_abbrev=home_abbrev,\n",
        "                    opponent_abbrev=away_abbrev,\n",
        "                    is_home=True\n",
        "                )\n",
        "\n",
        "                print(f\"\\nPrediction for {home_abbrev} vs {away_abbrev}:\")\n",
        "                print(f\"Win Probability for {home_abbrev}: {prediction['prediction']:.2%}\")\n",
        "                print(f\"Confidence: {prediction['confidence']:.2%}\")\n",
        "                print(\"\\nModel Predictions:\")\n",
        "                for model, pred in prediction['model_predictions'].items():\n",
        "                    print(f\"{model.capitalize()}: {pred:.2%}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error during prediction: {str(e)}\")\n",
        "                logging.error(f\"Prediction error: {traceback.format_exc()}\")\n",
        "\n",
        "    # Connect buttons to callbacks\n",
        "    train_button.on_click(on_train_button_clicked)\n",
        "    predict_button.on_click(on_predict_button_clicked)\n",
        "\n",
        "    # Display widgets\n",
        "    display(widgets.VBox([\n",
        "        widgets.HTML(\"<h3>NBA Game Prediction</h3>\"),\n",
        "        status_label,\n",
        "        widgets.HBox([home_team, away_team]),\n",
        "        widgets.HBox([train_button, predict_button]),\n",
        "        output\n",
        "    ]))\n",
        "\n",
        "# Create the interface when running this cell\n",
        "create_prediction_interface()"
      ],
      "metadata": {
        "id": "eEOrito4gRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870,
          "referenced_widgets": [
            "2c883cb0bd4d475da0daa7069b2188a4",
            "03cf8df14fb744e3b2ae79713ea63627",
            "d30e14ea32b2456db77278e02fe9219b",
            "fe729340ee374333845a9bee42d6d0b0",
            "899bee3331a3442192dc6569bd061ab2",
            "45b0391df2834c9f82b4785498db3c7b",
            "1080fcc23a9e414580ff0a178c063a73",
            "c37e85f658444b469114883ab6a1d2c4",
            "4fb5fdb222fb428ba8b74972ecc6bf50",
            "a7314aec0c15409189489fd6dab5d2dc",
            "cf6423da94a64aee8ec200f4312946f0",
            "138497201475493db193467240307980",
            "280c1aa78269409d84466829463776ef",
            "2f6cd8d7a2b545cc8299dc5a90dce241",
            "813fb70b2cfb4c6d814344252e8300be",
            "076a40bdc773402ca477b3bd4f254fe7",
            "ccb6de02b0b34a7c81f073c6ebf764eb",
            "d00f6198adf747c0901ac48136191501",
            "e9eb33218b4941b49e1fa94a60f4449d",
            "1cf883756eb34a0d88656b1765730100",
            "112262f55d6b42c9aa1f476223f6dde0",
            "b933c857ac5340feaca30058a624a269",
            "022c5e5586ff4e0ea7de93240c91c09c",
            "c78de212c4824e668e917402c4d3508a",
            "eacac327d2a84e90a7c9040ce0bdc635",
            "75d8df1af7d741038656ae7f42b7d0da"
          ]
        },
        "outputId": "13701297-7123-4817-8db4-7708c62a7ff2"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 19:47:14,811 - INFO - Found latest timestamp: 20241113_193935\n",
            "2024-11-13 19:47:14,879 - ERROR - Error loading models: can't set attribute 'booster_'\n",
            "2024-11-13 19:47:14,881 - ERROR - Full error: Traceback (most recent call last):\n",
            "  File \"<ipython-input-192-a0b171efd0f6>\", line 174, in load_most_recent_models\n",
            "    lgb_model.booster_ = lgb.Booster(model_file=str(lgb_path))\n",
            "AttributeError: can't set attribute 'booster_'\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h3>NBA Game Prediction</h3>'), HTML(value='<p style=\"color: red;\">No models loaded…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c883cb0bd4d475da0daa7069b2188a4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Initialization of Components\n",
        "\n",
        "# Initialize components\n",
        "logging.info(\"Initializing components...\")\n",
        "data_manager = DataManager()\n",
        "processor = DataProcessor()\n",
        "trainer = ModelTrainer()\n",
        "\n",
        "# Fetch data\n",
        "logging.info(\"Fetching NBA data...\")\n",
        "game_data = fetch_or_load_data()\n",
        "if game_data.empty:\n",
        "    logging.error(\"No game data available.\")\n",
        "else:\n",
        "    # Preprocess data\n",
        "    logging.info(\"Preprocessing game data...\")\n",
        "    features = processor.preprocess_game_data(game_data)\n",
        "    features = processor.prepare_features(features)\n",
        "\n",
        "    # Split the dataset into features and target\n",
        "    X = features.drop(['GAME_DATE', 'WIN'], axis=1)\n",
        "    y = features['WIN']\n",
        "\n",
        "    # Split data into training, validation, and test sets\n",
        "    train_size = int(0.7 * len(features))\n",
        "    val_size = int(0.15 * len(features))\n",
        "\n",
        "    X_train, y_train = X[:train_size], y[:train_size]\n",
        "    X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]\n",
        "    X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]\n",
        "\n",
        "    # Train models\n",
        "    logging.info(\"Training models...\")\n",
        "    models = trainer.train_models(X_train, X_val, X_test, y_train, y_val, y_test)\n",
        "    scaler = trainer.scaler\n",
        "\n",
        "    # Save models and scaler\n",
        "    logging.info(\"Saving models...\")\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    joblib.dump(models[0], f'{NotebookConfig.MODELS_DIR}/baseline_model_{timestamp}.joblib')\n",
        "    models[1].save_model(f'{NotebookConfig.MODELS_DIR}/xgb_model_{timestamp}.json')\n",
        "    models[2].booster_.save_model(f'{NotebookConfig.MODELS_DIR}/lgb_model_{timestamp}.txt')\n",
        "    models[3].save(f'{NotebookConfig.MODELS_DIR}/nn_model_{timestamp}.h5')\n",
        "    with open(f'{NotebookConfig.MODELS_DIR}/scaler_{timestamp}.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "    logging.info(\"Initialization and training completed.\")"
      ],
      "metadata": {
        "id": "znuXhUW6gUHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6aec8a6-6122-4c78-a5d3-8dcf790b2a31"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 19:56:25,910 - INFO - Initializing components...\n",
            "2024-11-13 19:56:25,913 - INFO - Fetching NBA data...\n",
            "2024-11-13 19:56:25,967 - INFO - Data loaded from /content/drive/MyDrive/nba_models/cache/nba_game_data.pkl\n",
            "2024-11-13 19:56:25,985 - INFO - Cache is fresh, loading data from cache.\n",
            "2024-11-13 19:56:25,988 - INFO - Preprocessing game data...\n",
            "2024-11-13 19:56:25,990 - INFO - Initial data shape: (30000, 28)\n",
            "2024-11-13 19:56:25,994 - INFO - Initial columns: Index(['SEASON_ID', 'TEAM_ID', 'TEAM_ABBREVIATION', 'TEAM_NAME', 'GAME_ID',\n",
            "       'GAME_DATE', 'MATCHUP', 'WL', 'MIN', 'PTS', 'FGM', 'FGA', 'FG_PCT',\n",
            "       'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB',\n",
            "       'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PLUS_MINUS'],\n",
            "      dtype='object')\n",
            "2024-11-13 19:56:26,025 - INFO - Created WIN column from WL\n",
            "2024-11-13 19:56:26,209 - INFO - After date conversion shape: (30000, 29)\n",
            "2024-11-13 19:56:26,239 - INFO - After team abbreviation mapping shape: (30000, 29)\n",
            "2024-11-13 19:56:27,541 - WARNING - Missing opponent team IDs for: ['USA' 'WLD' 'NGR' 'AUS' 'ARG' 'ESP' 'CAN' 'SRB' 'SUD' 'GER' 'SKO' 'GLI'\n",
            " 'LVA' 'CLG' 'MGG' 'HCG' 'TWG' 'NGC' 'WDG' 'GZG' 'MVG' 'KNX' 'BCG' 'KGG'\n",
            " 'RUG' 'HVG' 'BZG' 'CCG' 'HTG' 'GEN' 'WGS' 'LKG' 'DUX' 'JZG' 'DOT' 'PCG'\n",
            " 'PGT' 'NBL' 'DGZ' 'RRS' 'SGC' 'XST' 'GLO' 'GCL' 'ABS' 'INT' 'NYI' 'HDZ'\n",
            " 'DSH' 'CTH' 'EUR' 'TTH' 'APC' 'GLU' 'KMB' 'TTG' 'TTW' 'STA' 'HER' 'TOW'\n",
            " 'TFG' 'FOR' 'LOV' 'MRA' 'RMD' 'SKT' 'FLA' 'NZB' 'ADL' 'ULM' 'UTW' 'UTB'\n",
            " 'CHN' 'CNS' 'LBN' 'WST' 'GNS' 'DRT' 'EST' 'WLB' 'WAL' 'RYN' 'NIQ' 'DWN'\n",
            " 'SHN' 'IAH' 'PAY' 'DRN' 'JKM' 'DLF' 'BAR' 'PAU' 'JAL' 'WOR' 'JAS' 'TAM'\n",
            " 'SEA' 'PHO' 'LAS' 'CON' 'NYL' 'PUR' 'WIL' 'STW' 'WNT' 'TMW' 'SLC' 'RGV'\n",
            " 'IWA' 'ERI' 'WES' 'ACC' 'SXF' 'CAP' 'RAP' 'NAS' 'SBL' 'STO' 'SCW' 'TEX'\n",
            " 'MHU' 'LIN' 'CTN' 'FWN' 'LAK' 'GBO' 'DEL' 'MCC' 'BIR' 'MXC' 'GRG' 'BHM'\n",
            " 'CPS' 'ONT' 'OSC' 'WIS' 'CLC' 'MNE' 'RCR' 'WCB' 'OKL' 'GRD' 'IMA' 'VAL'\n",
            " 'LUK' 'SCT' 'PER' 'SDC' 'EYL' 'BIL' 'STR' 'GIR' 'LEG' 'BEL' 'KIP' 'ARI'\n",
            " 'RED' 'WHT']\n",
            "2024-11-13 19:56:27,555 - INFO - After dropping missing opponents shape: (14678, 36)\n",
            "2024-11-13 19:56:27,586 - INFO - Adding fatigue features...\n",
            "2024-11-13 19:56:35,275 - INFO - Adding advanced features...\n",
            "2024-11-13 19:56:36,011 - INFO - Adding rolling stats...\n",
            "2024-11-13 19:56:37,708 - INFO - Adding head-to-head features...\n",
            "2024-11-13 19:56:38,507 - INFO - Adding streak features...\n",
            "2024-11-13 19:56:41,722 - INFO - Adding time-based features...\n",
            "2024-11-13 19:56:41,723 - INFO - Starting add_time_based_features\n",
            "2024-11-13 19:56:41,729 - INFO - Initial shape: (14678, 116)\n",
            "2024-11-13 19:56:41,746 - INFO - Final shape after time-based features: (14678, 119)\n",
            "2024-11-13 19:56:41,929 - INFO - Final shape: (14678, 119)\n",
            "2024-11-13 19:56:42,083 - INFO - Training models...\n",
            "2024-11-13 19:56:42,084 - INFO - Preprocessing features...\n",
            "2024-11-13 19:56:42,167 - INFO - Training baseline Logistic Regression model...\n",
            "2024-11-13 19:56:42,344 - INFO - Baseline Logistic Regression Evaluation:\n",
            "2024-11-13 19:56:42,345 - INFO -   Accuracy: 1.0000\n",
            "2024-11-13 19:56:42,350 - INFO -   F1 Score: 1.0000\n",
            "2024-11-13 19:56:42,354 - INFO -   ROC AUC: 1.0000\n",
            "2024-11-13 19:56:42,355 - INFO -   Precision: 1.0000\n",
            "2024-11-13 19:56:42,362 - INFO -   Recall: 1.0000\n",
            "2024-11-13 19:56:42,367 - INFO -   Confusion Matrix:\n",
            "2024-11-13 19:56:42,370 - INFO -     TN: 1090, FP: 0\n",
            "2024-11-13 19:56:42,371 - INFO -     FN: 0, TP: 1113\n",
            "2024-11-13 19:56:42,375 - INFO - Training XGBoost model...\n",
            "[I 2024-11-13 19:56:42,377] A new study created in memory with name: no-name-1e5e2e74-1166-4cae-a1df-9acb017abfd8\n",
            "[I 2024-11-13 19:56:44,057] Trial 0 finished with value: 1.0 and parameters: {'max_depth': 5, 'learning_rate': 0.09780129094482347, 'n_estimators': 99, 'min_child_weight': 6, 'subsample': 0.7953736086345471, 'colsample_bytree': 0.6762922071723503, 'gamma': 0.5255671624117315}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:56:52,775] Trial 1 finished with value: 1.0 and parameters: {'max_depth': 5, 'learning_rate': 0.017771939532831797, 'n_estimators': 268, 'min_child_weight': 4, 'subsample': 0.6181926302909059, 'colsample_bytree': 0.6122134339335599, 'gamma': 1.9719966510295321}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:56:56,755] Trial 2 finished with value: 1.0 and parameters: {'max_depth': 6, 'learning_rate': 0.050370807974078106, 'n_estimators': 227, 'min_child_weight': 7, 'subsample': 0.6613563632130358, 'colsample_bytree': 0.8853238199902602, 'gamma': 0.10863996160365819}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:56:59,489] Trial 3 finished with value: 1.0 and parameters: {'max_depth': 3, 'learning_rate': 0.011900731014016997, 'n_estimators': 106, 'min_child_weight': 7, 'subsample': 0.7124407480670082, 'colsample_bytree': 0.8631420614656554, 'gamma': 0.05888465633582873}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:03,379] Trial 4 finished with value: 1.0 and parameters: {'max_depth': 6, 'learning_rate': 0.052517411033425276, 'n_estimators': 122, 'min_child_weight': 5, 'subsample': 0.8601809241166826, 'colsample_bytree': 0.6479443223440176, 'gamma': 1.8260137713757472}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:08,965] Trial 5 finished with value: 1.0 and parameters: {'max_depth': 6, 'learning_rate': 0.040307239560257314, 'n_estimators': 174, 'min_child_weight': 1, 'subsample': 0.7962400707727834, 'colsample_bytree': 0.7005430124155488, 'gamma': 0.3142539119448784}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:12,173] Trial 6 finished with value: 1.0 and parameters: {'max_depth': 4, 'learning_rate': 0.09422942287036672, 'n_estimators': 230, 'min_child_weight': 5, 'subsample': 0.8932692074549653, 'colsample_bytree': 0.8698662065936358, 'gamma': 1.8035306975621064}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:15,788] Trial 7 finished with value: 1.0 and parameters: {'max_depth': 5, 'learning_rate': 0.07699063122011365, 'n_estimators': 246, 'min_child_weight': 4, 'subsample': 0.8785678478448044, 'colsample_bytree': 0.8431892537752975, 'gamma': 0.9384319202247147}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:23,222] Trial 8 finished with value: 1.0 and parameters: {'max_depth': 3, 'learning_rate': 0.05703557485724422, 'n_estimators': 197, 'min_child_weight': 3, 'subsample': 0.8322034545480483, 'colsample_bytree': 0.7684397696365048, 'gamma': 1.0718215828347024}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:25,017] Trial 9 finished with value: 1.0 and parameters: {'max_depth': 6, 'learning_rate': 0.015656651225892347, 'n_estimators': 83, 'min_child_weight': 5, 'subsample': 0.6523464928656737, 'colsample_bytree': 0.6929033552918309, 'gamma': 0.5820188428571587}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:26,431] Trial 10 finished with value: 1.0 and parameters: {'max_depth': 2, 'learning_rate': 0.09587363696659991, 'n_estimators': 58, 'min_child_weight': 6, 'subsample': 0.7435304050665207, 'colsample_bytree': 0.782972482301507, 'gamma': 1.3338823842391825}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:30,858] Trial 11 finished with value: 1.0 and parameters: {'max_depth': 5, 'learning_rate': 0.02996626435120638, 'n_estimators': 300, 'min_child_weight': 3, 'subsample': 0.6009826957762279, 'colsample_bytree': 0.6014689097420003, 'gamma': 0.6370543458127305}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:35,858] Trial 12 finished with value: 1.0 and parameters: {'max_depth': 5, 'learning_rate': 0.07446482507081274, 'n_estimators': 147, 'min_child_weight': 3, 'subsample': 0.792804490476427, 'colsample_bytree': 0.6092510843728349, 'gamma': 1.4503363646819647}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:40,632] Trial 13 finished with value: 1.0 and parameters: {'max_depth': 4, 'learning_rate': 0.070304637778194, 'n_estimators': 292, 'min_child_weight': 1, 'subsample': 0.7117449034503134, 'colsample_bytree': 0.6599152315417292, 'gamma': 0.6660970069590615}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:43,963] Trial 14 finished with value: 1.0 and parameters: {'max_depth': 5, 'learning_rate': 0.029330365148215617, 'n_estimators': 157, 'min_child_weight': 6, 'subsample': 0.7993874836150675, 'colsample_bytree': 0.7251258061193596, 'gamma': 1.9891566692359384}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:47,157] Trial 15 finished with value: 1.0 and parameters: {'max_depth': 4, 'learning_rate': 0.08604191534429116, 'n_estimators': 264, 'min_child_weight': 4, 'subsample': 0.6199843773872428, 'colsample_bytree': 0.6534857020994853, 'gamma': 1.4834216546074335}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:50,690] Trial 16 finished with value: 1.0 and parameters: {'max_depth': 5, 'learning_rate': 0.06356832207248397, 'n_estimators': 51, 'min_child_weight': 2, 'subsample': 0.7511052232243715, 'colsample_bytree': 0.6315662311905506, 'gamma': 0.9721107694381484}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:56,007] Trial 17 finished with value: 1.0 and parameters: {'max_depth': 3, 'learning_rate': 0.0238132559421402, 'n_estimators': 202, 'min_child_weight': 6, 'subsample': 0.6917394141458475, 'colsample_bytree': 0.686309182273681, 'gamma': 0.314878597525694}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:57:58,629] Trial 18 finished with value: 1.0 and parameters: {'max_depth': 4, 'learning_rate': 0.04100838137210763, 'n_estimators': 124, 'min_child_weight': 4, 'subsample': 0.8305513032273835, 'colsample_bytree': 0.7262132769244124, 'gamma': 1.1780049496080278}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-11-13 19:58:02,260] Trial 19 finished with value: 1.0 and parameters: {'max_depth': 5, 'learning_rate': 0.08468628435309367, 'n_estimators': 263, 'min_child_weight': 5, 'subsample': 0.7575430280546053, 'colsample_bytree': 0.7975965142579808, 'gamma': 0.8291756234566173}. Best is trial 0 with value: 1.0.\n",
            "2024-11-13 19:58:03,623 - INFO - XGBoost Evaluation:\n",
            "2024-11-13 19:58:03,627 - INFO -   Accuracy: 1.0000\n",
            "2024-11-13 19:58:03,633 - INFO -   F1 Score: 1.0000\n",
            "2024-11-13 19:58:03,637 - INFO -   ROC AUC: 1.0000\n",
            "2024-11-13 19:58:03,641 - INFO -   Precision: 1.0000\n",
            "2024-11-13 19:58:03,643 - INFO -   Recall: 1.0000\n",
            "2024-11-13 19:58:03,649 - INFO -   Confusion Matrix:\n",
            "2024-11-13 19:58:03,655 - INFO -     TN: 1090, FP: 0\n",
            "2024-11-13 19:58:03,657 - INFO -     FN: 0, TP: 1113\n",
            "2024-11-13 19:58:03,659 - INFO - Training LightGBM model...\n",
            "[I 2024-11-13 19:58:03,660] A new study created in memory with name: no-name-3dc4e9d9-e21c-4eff-a06f-a056c0d9fc91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=13 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=13 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:07,428] Trial 0 finished with value: 1.0 and parameters: {'num_leaves': 25, 'learning_rate': 0.03689013247052946, 'n_estimators': 191, 'min_child_samples': 13, 'subsample': 0.747450879777221, 'colsample_bytree': 0.8603376241485899}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=13 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=28 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=28 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:08,909] Trial 1 finished with value: 1.0 and parameters: {'num_leaves': 9, 'learning_rate': 0.02988568047253621, 'n_estimators': 133, 'min_child_samples': 28, 'subsample': 0.7685098017527628, 'colsample_bytree': 0.6538595859049122}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=28 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=42 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=42 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:10,302] Trial 2 finished with value: 1.0 and parameters: {'num_leaves': 11, 'learning_rate': 0.0280301632583062, 'n_estimators': 157, 'min_child_samples': 42, 'subsample': 0.8578470410547561, 'colsample_bytree': 0.6159593155225976}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=42 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=39 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=39 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:11,420] Trial 3 finished with value: 1.0 and parameters: {'num_leaves': 16, 'learning_rate': 0.06619541461560273, 'n_estimators': 105, 'min_child_samples': 39, 'subsample': 0.8098672503627985, 'colsample_bytree': 0.6794067836741787}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=39 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=14 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=14 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:13,151] Trial 4 finished with value: 1.0 and parameters: {'num_leaves': 28, 'learning_rate': 0.05334097327273916, 'n_estimators': 127, 'min_child_samples': 14, 'subsample': 0.8014128094737025, 'colsample_bytree': 0.6844445990314464}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=14 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=21 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=21 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:16,805] Trial 5 finished with value: 1.0 and parameters: {'num_leaves': 27, 'learning_rate': 0.0326565902147186, 'n_estimators': 282, 'min_child_samples': 21, 'subsample': 0.6783886266080315, 'colsample_bytree': 0.8631040537325656}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=21 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=13 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=13 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:17,962] Trial 6 finished with value: 1.0 and parameters: {'num_leaves': 16, 'learning_rate': 0.023166370768851446, 'n_estimators': 101, 'min_child_samples': 13, 'subsample': 0.6131909422135272, 'colsample_bytree': 0.8460619430398518}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=13 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=18 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=18 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:19,710] Trial 7 finished with value: 1.0 and parameters: {'num_leaves': 23, 'learning_rate': 0.07844816725210269, 'n_estimators': 92, 'min_child_samples': 18, 'subsample': 0.634164953114548, 'colsample_bytree': 0.6111847477347211}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=18 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=18 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=18 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:22,441] Trial 8 finished with value: 1.0 and parameters: {'num_leaves': 19, 'learning_rate': 0.0809756084881905, 'n_estimators': 159, 'min_child_samples': 18, 'subsample': 0.8304493631890396, 'colsample_bytree': 0.8211078865020347}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=18 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=34 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=34 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:24,457] Trial 9 finished with value: 1.0 and parameters: {'num_leaves': 18, 'learning_rate': 0.09686803738994959, 'n_estimators': 129, 'min_child_samples': 34, 'subsample': 0.848294292083259, 'colsample_bytree': 0.7960331440500917}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=34 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=27 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=27 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:27,794] Trial 10 finished with value: 1.0 and parameters: {'num_leaves': 31, 'learning_rate': 0.048115373874781986, 'n_estimators': 226, 'min_child_samples': 27, 'subsample': 0.7116160388899516, 'colsample_bytree': 0.7553859138259016}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=27 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:29,432] Trial 11 finished with value: 1.0 and parameters: {'num_leaves': 8, 'learning_rate': 0.039701523696677024, 'n_estimators': 212, 'min_child_samples': 50, 'subsample': 0.7586350869335764, 'colsample_bytree': 0.8908084046747187}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:31,968] Trial 12 finished with value: 1.0 and parameters: {'num_leaves': 24, 'learning_rate': 0.01439293012813233, 'n_estimators': 202, 'min_child_samples': 25, 'subsample': 0.7534300257936692, 'colsample_bytree': 0.7024454264838752}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=32 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=32 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:32,646] Trial 13 finished with value: 1.0 and parameters: {'num_leaves': 12, 'learning_rate': 0.011903536621655712, 'n_estimators': 51, 'min_child_samples': 32, 'subsample': 0.7069389590853646, 'colsample_bytree': 0.7626750959880264}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=32 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=11 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=11 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:36,670] Trial 14 finished with value: 1.0 and parameters: {'num_leaves': 23, 'learning_rate': 0.0393321345910803, 'n_estimators': 254, 'min_child_samples': 11, 'subsample': 0.8871931539760917, 'colsample_bytree': 0.7224857562886556}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=11 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:40,625] Trial 15 finished with value: 1.0 and parameters: {'num_leaves': 32, 'learning_rate': 0.06176459924572494, 'n_estimators': 182, 'min_child_samples': 25, 'subsample': 0.7825155254873574, 'colsample_bytree': 0.6317998061037}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=37 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=37 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:42,238] Trial 16 finished with value: 1.0 and parameters: {'num_leaves': 13, 'learning_rate': 0.04237565468104472, 'n_estimators': 178, 'min_child_samples': 37, 'subsample': 0.7079770995065905, 'colsample_bytree': 0.6571294237433356}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=37 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=46 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=46 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:43,980] Trial 17 finished with value: 1.0 and parameters: {'num_leaves': 8, 'learning_rate': 0.021493633150135423, 'n_estimators': 237, 'min_child_samples': 46, 'subsample': 0.6555901290650435, 'colsample_bytree': 0.7902123217028545}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=46 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:44,853] Trial 18 finished with value: 1.0 and parameters: {'num_leaves': 26, 'learning_rate': 0.031884357862982535, 'n_estimators': 50, 'min_child_samples': 30, 'subsample': 0.77448766747249, 'colsample_bytree': 0.7271889624582539}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=30 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=21 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=21 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-13 19:58:46,653] Trial 19 finished with value: 1.0 and parameters: {'num_leaves': 21, 'learning_rate': 0.06028468788880089, 'n_estimators': 141, 'min_child_samples': 21, 'subsample': 0.7086412587526603, 'colsample_bytree': 0.8893459816637278}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=21 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 5174, number of negative: 5100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015366 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 17782\n",
            "[LightGBM] [Info] Number of data points in the train set: 10274, number of used features: 111\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503601 -> initscore=0.014406\n",
            "[LightGBM] [Info] Start training from score 0.014406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 19:58:49,140 - INFO - LightGBM Evaluation:\n",
            "2024-11-13 19:58:49,142 - INFO -   Accuracy: 1.0000\n",
            "2024-11-13 19:58:49,144 - INFO -   F1 Score: 1.0000\n",
            "2024-11-13 19:58:49,146 - INFO -   ROC AUC: 1.0000\n",
            "2024-11-13 19:58:49,148 - INFO -   Precision: 1.0000\n",
            "2024-11-13 19:58:49,150 - INFO -   Recall: 1.0000\n",
            "2024-11-13 19:58:49,154 - INFO -   Confusion Matrix:\n",
            "2024-11-13 19:58:49,156 - INFO -     TN: 1090, FP: 0\n",
            "2024-11-13 19:58:49,157 - INFO -     FN: 0, TP: 1113\n",
            "2024-11-13 19:58:49,158 - INFO - Training Neural Network model...\n",
            "2024-11-13 19:58:49,159 - INFO - Creating neural network with input dimension: 111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7436 - loss: 1.7870 - val_accuracy: 0.9696 - val_loss: 0.9578 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.7348 - val_accuracy: 0.9932 - val_loss: 0.3813 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.3556 - val_accuracy: 0.9964 - val_loss: 0.1933 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.2068 - val_accuracy: 0.9945 - val_loss: 0.1249 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.1334 - val_accuracy: 0.9959 - val_loss: 0.0897 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.1350 - val_accuracy: 0.9950 - val_loss: 0.1028 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.1069 - val_accuracy: 0.9964 - val_loss: 0.0956 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.1049 - val_accuracy: 0.9968 - val_loss: 0.0729 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0915 - val_accuracy: 0.9986 - val_loss: 0.0639 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0746 - val_accuracy: 0.9977 - val_loss: 0.0635 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.1058 - val_accuracy: 0.9905 - val_loss: 0.1141 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.1749 - val_accuracy: 0.9982 - val_loss: 0.0940 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.1131 - val_accuracy: 0.9977 - val_loss: 0.0914 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9883 - loss: 0.1064 - val_accuracy: 0.9973 - val_loss: 0.0836 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.0969 - val_accuracy: 0.9945 - val_loss: 0.0700 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0970 - val_accuracy: 0.9991 - val_loss: 0.0754 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0855 - val_accuracy: 0.9991 - val_loss: 0.0596 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0636 - val_accuracy: 0.9973 - val_loss: 0.0638 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0724 - val_accuracy: 0.9977 - val_loss: 0.0563 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0592 - val_accuracy: 0.9977 - val_loss: 0.0542 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 0.0625 - val_accuracy: 0.9936 - val_loss: 0.0559 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.1330 - val_accuracy: 0.9982 - val_loss: 0.0736 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0902 - val_accuracy: 0.9973 - val_loss: 0.0794 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0959 - val_accuracy: 0.9973 - val_loss: 0.0627 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0752 - val_accuracy: 0.9977 - val_loss: 0.0559 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0643 - val_accuracy: 0.9977 - val_loss: 0.0491 - learning_rate: 0.0010\n",
            "Epoch 27/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0612 - val_accuracy: 0.9991 - val_loss: 0.0431 - learning_rate: 0.0010\n",
            "Epoch 28/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0583 - val_accuracy: 0.9968 - val_loss: 0.0630 - learning_rate: 0.0010\n",
            "Epoch 29/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0565 - val_accuracy: 0.9982 - val_loss: 0.0413 - learning_rate: 0.0010\n",
            "Epoch 30/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0537 - val_accuracy: 0.9986 - val_loss: 0.0504 - learning_rate: 0.0010\n",
            "Epoch 31/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0533 - val_accuracy: 0.9986 - val_loss: 0.0429 - learning_rate: 0.0010\n",
            "Epoch 32/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0743 - val_accuracy: 0.9950 - val_loss: 0.0808 - learning_rate: 0.0010\n",
            "Epoch 33/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0757 - val_accuracy: 0.9982 - val_loss: 0.0603 - learning_rate: 0.0010\n",
            "Epoch 34/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0548 - val_accuracy: 0.9964 - val_loss: 0.0755 - learning_rate: 0.0010\n",
            "Epoch 35/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0510 - val_accuracy: 0.9986 - val_loss: 0.0827 - learning_rate: 0.0010\n",
            "Epoch 36/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0482 - val_accuracy: 0.9973 - val_loss: 0.0794 - learning_rate: 0.0010\n",
            "Epoch 37/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 0.0564 - val_accuracy: 0.9968 - val_loss: 0.0777 - learning_rate: 0.0010\n",
            "Epoch 38/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0492 - val_accuracy: 0.9982 - val_loss: 0.0423 - learning_rate: 0.0010\n",
            "Epoch 39/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0508 - val_accuracy: 0.9973 - val_loss: 0.0494 - learning_rate: 0.0010\n",
            "Epoch 40/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0478 - val_accuracy: 0.9977 - val_loss: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0410 - val_accuracy: 0.9995 - val_loss: 0.0287 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 0.0343 - val_accuracy: 0.9977 - val_loss: 0.0332 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0307 - val_accuracy: 0.9995 - val_loss: 0.0243 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0261 - val_accuracy: 0.9991 - val_loss: 0.0345 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0271 - val_accuracy: 0.9991 - val_loss: 0.0286 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0292 - val_accuracy: 0.9968 - val_loss: 0.0385 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0272 - val_accuracy: 0.9964 - val_loss: 0.0457 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0298 - val_accuracy: 0.9982 - val_loss: 0.0285 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0292 - val_accuracy: 0.9982 - val_loss: 0.0393 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0280 - val_accuracy: 0.9986 - val_loss: 0.0368 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0243 - val_accuracy: 0.9991 - val_loss: 0.0280 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0280 - val_accuracy: 0.9982 - val_loss: 0.0375 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0371 - val_accuracy: 0.9991 - val_loss: 0.0284 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0258 - val_accuracy: 0.9991 - val_loss: 0.0254 - learning_rate: 2.5000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0247 - val_accuracy: 0.9986 - val_loss: 0.0305 - learning_rate: 2.5000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0277 - val_accuracy: 0.9991 - val_loss: 0.0192 - learning_rate: 2.5000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0232 - val_accuracy: 0.9995 - val_loss: 0.0190 - learning_rate: 2.5000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0198 - val_accuracy: 0.9959 - val_loss: 0.0286 - learning_rate: 2.5000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0204 - val_accuracy: 0.9950 - val_loss: 0.0292 - learning_rate: 2.5000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0237 - val_accuracy: 0.9986 - val_loss: 0.0185 - learning_rate: 2.5000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0228 - val_accuracy: 0.9991 - val_loss: 0.0202 - learning_rate: 2.5000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0189 - val_accuracy: 0.9991 - val_loss: 0.0207 - learning_rate: 2.5000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0199 - val_accuracy: 0.9986 - val_loss: 0.0285 - learning_rate: 2.5000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0171 - val_accuracy: 0.9986 - val_loss: 0.0327 - learning_rate: 2.5000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0217 - val_accuracy: 0.9991 - val_loss: 0.0137 - learning_rate: 2.5000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0261 - val_accuracy: 0.9991 - val_loss: 0.0420 - learning_rate: 2.5000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0209 - val_accuracy: 0.9995 - val_loss: 0.0394 - learning_rate: 2.5000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0174 - val_accuracy: 0.9991 - val_loss: 0.0326 - learning_rate: 2.5000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0208 - val_accuracy: 0.9995 - val_loss: 0.0354 - learning_rate: 2.5000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0269 - val_accuracy: 0.9986 - val_loss: 0.0391 - learning_rate: 2.5000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0188 - val_accuracy: 0.9986 - val_loss: 0.0679 - learning_rate: 2.5000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0164 - val_accuracy: 0.9986 - val_loss: 0.0486 - learning_rate: 2.5000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0173 - val_accuracy: 0.9991 - val_loss: 0.0549 - learning_rate: 2.5000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0153 - val_accuracy: 0.9991 - val_loss: 0.0425 - learning_rate: 2.5000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0151 - val_accuracy: 0.9986 - val_loss: 0.0542 - learning_rate: 2.5000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0169 - val_accuracy: 0.9991 - val_loss: 0.0390 - learning_rate: 1.2500e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0154 - val_accuracy: 0.9991 - val_loss: 0.0429 - learning_rate: 1.2500e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0135 - val_accuracy: 0.9991 - val_loss: 0.0417 - learning_rate: 1.2500e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0132 - val_accuracy: 0.9991 - val_loss: 0.0293 - learning_rate: 1.2500e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0189 - val_accuracy: 0.9991 - val_loss: 0.0313 - learning_rate: 1.2500e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0144 - val_accuracy: 0.9986 - val_loss: 0.0458 - learning_rate: 1.2500e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0154 - val_accuracy: 0.9986 - val_loss: 0.0500 - learning_rate: 1.2500e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0123 - val_accuracy: 0.9986 - val_loss: 0.0409 - learning_rate: 1.2500e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0123 - val_accuracy: 0.9991 - val_loss: 0.0300 - learning_rate: 1.2500e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0112 - val_accuracy: 0.9991 - val_loss: 0.0305 - learning_rate: 1.2500e-04\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 20:01:57,479 - INFO - Neural Network Evaluation:\n",
            "2024-11-13 20:01:57,482 - INFO -   Accuracy: 1.0000\n",
            "2024-11-13 20:01:57,483 - INFO -   F1 Score: 1.0000\n",
            "2024-11-13 20:01:57,486 - INFO -   ROC AUC: 1.0000\n",
            "2024-11-13 20:01:57,494 - INFO -   Precision: 1.0000\n",
            "2024-11-13 20:01:57,501 - INFO -   Recall: 1.0000\n",
            "2024-11-13 20:01:57,514 - INFO -   Confusion Matrix:\n",
            "2024-11-13 20:01:57,518 - INFO -     TN: 1090, FP: 0\n",
            "2024-11-13 20:01:57,523 - INFO -     FN: 0, TP: 1113\n",
            "2024-11-13 20:01:57,528 - INFO - Saving models...\n",
            "2024-11-13 20:01:57,616 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "2024-11-13 20:01:57,786 - INFO - Initialization and training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Game Schedule and Predictions Formatter\n",
        "# This class formats predictions for upcoming games.\n",
        "\n",
        "class NBAGamePredictor:\n",
        "    def __init__(self, models, scaler, processor):\n",
        "        self.predictor = GamePredictor(models, scaler, processor)\n",
        "        self.config = NotebookConfig()\n",
        "\n",
        "    def fetch_upcoming_games(self):\n",
        "        \"\"\"Fetch upcoming NBA games and odds.\"\"\"\n",
        "        params = {\n",
        "            'apiKey': self.config.ODDS_API_KEY,\n",
        "            'regions': self.config.REGIONS,\n",
        "            'markets': 'h2h',\n",
        "            'oddsFormat': self.config.ODDS_FORMAT\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(self.config.ODDS_API_URL, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            else:\n",
        "                logging.error(f\"Error fetching odds: {response.status_code}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error fetching upcoming games: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def format_predictions(self):\n",
        "        \"\"\"Format predictions for upcoming games.\"\"\"\n",
        "        games = self.fetch_upcoming_games()\n",
        "        if not games:\n",
        "            return \"Unable to fetch upcoming games\"\n",
        "\n",
        "        output = \"Model Predictions:\\n\"\n",
        "        for game in games:\n",
        "            home_team = game['home_team']\n",
        "            away_team = game['away_team']\n",
        "\n",
        "            # Get win probabilities\n",
        "            home_pred = self.predictor.predict_game(pd.DataFrame([{\n",
        "                'TEAM_ABBREVIATION': home_team,\n",
        "                'OPPONENT_ABBREV': away_team,\n",
        "                'GAME_DATE': datetime.now().strftime('%Y-%m-%d'),\n",
        "                'MATCHUP': f\"{home_team} vs. {away_team}\",\n",
        "                'WL': 'W'  # Placeholder\n",
        "            }]))['prediction']\n",
        "\n",
        "            output += f\"{home_team} vs {away_team} - {home_team} Win Probability: {home_pred:.2%}\\n\"\n",
        "\n",
        "        return output\n",
        "\n",
        "# Test NBAGamePredictor class\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Assume models, scaler, and processor are already initialized\n",
        "        nba_predictor = NBAGamePredictor(models, scaler, processor)\n",
        "        predictions_output = nba_predictor.format_predictions()\n",
        "        print(predictions_output)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error running predictions: {str(e)}\")"
      ],
      "metadata": {
        "id": "FkUkII3OgWHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af52761-e505-4bcb-c530-dcd5d58c8aba"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-13 20:02:05,459 - ERROR - Error running predictions: GamePredictor.predict_game() missing 1 required positional argument: 'opponent_abbrev'\n"
          ]
        }
      ]
    }
  ]
}